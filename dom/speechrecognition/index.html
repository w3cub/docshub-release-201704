
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>SpeechRecognition - DOM - W3cubDocs</title>
  
  <meta name="description" content="This is an experimental technologyBecause this technology&#39;s specification has not stabilized, check the compatibility table for usage in various &hellip;">
  <meta name="keywords" content="speechrecognition, -, dom">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/dom/speechrecognition/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/dom.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/dom/" class="_nav-link" title="" style="margin-left:0;">DOM</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _mdn">
				
<h1>SpeechRecognition</h1>
<div class="notice experimental"> <p> <strong>This is an experimental technology</strong><br>Because this technology's specification has not stabilized, check the <a href="#Browser_compatibility">compatibility table</a> for usage in various browsers. Also note that the syntax and behavior of an experimental technology is subject to change in future versions of browsers as the specification changes.</p> </div> <p>The <strong><code>SpeechRecognition</code></strong> interface of the <a href="../web_speech_api/">Web Speech API</a> is the controller interface for the recognition service; this also handles the <a title="The SpeechRecognitionEvent interface of the Web Speech API represents the event object for the result and nomatch events, and contains all the data associated with an interim or final speech recognition result." href="../speechrecognitionevent/"><code>SpeechRecognitionEvent</code></a> sent from the recognition service.</p> <h2 id="Constructor">Constructor</h2> <dl> <dt><a title="The SpeechRecognition() constructor creates a new SpeechRecognition object instance." href="../speechrecognition/speechrecognition/"><code>SpeechRecognition.SpeechRecognition()</code></a></dt> <dd>Creates a new <code>SpeechRecognition</code> object.</dd> </dl> <h2 id="Properties">Properties</h2> <p><em><code>SpeechRecognition</code> also inherits properties from its parent interface, <a title="EventTarget is an interface implemented by objects that can receive events and may have listeners for them." href="../eventtarget/"><code>EventTarget</code></a>.</em></p> <dl> <dt><a title="The grammars property of the SpeechRecognition interface returns and sets a collection of SpeechGrammar objects that represent the grammars that will be understood by the current SpeechRecognition." href="../speechrecognition/grammars/"><code>SpeechRecognition.grammars</code></a></dt> <dd>Returns and sets a collection of <a title="The SpeechGrammar interface of the Web Speech API represents a set of words or patterns of words that we want the recognition service to recognize." href="../speechgrammar/"><code>SpeechGrammar</code></a> objects that represent the grammars that will be understood by the current <code>SpeechRecognition</code>.</dd> <dt><a title="The lang property of the SpeechRecognition interface returns and sets the language of the current SpeechRecognition. If not specified, this defaults to the HTML lang attribute value, or the user agent's language setting if that isn't set either." href="../speechrecognition/lang/"><code>SpeechRecognition.lang</code></a></dt> <dd>Returns and sets the language of the current <code>SpeechRecognition</code>. If not specified, this defaults to the HTML <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/html#attr-lang" target="_blank">lang</a></code> attribute value, or the user agent's language setting if that isn't set either.</dd> <dt><a title="The continuous property of the SpeechRecognition interface controls whether continuous results are returned for each recognition, or only a single result." href="../speechrecognition/continuous/"><code>SpeechRecognition.continuous</code></a></dt> <dd>Controls whether continuous results are returned for each recognition, or only a single result. Defaults to single (<code>false</code>.)</dd> <dt><a title="The interimResults property of the SpeechRecognition interface controls whether interim results should be returned (true) or not (false.) Interim results are results that are not yet final (e.g. the SpeechRecognitionResult.isFinal property is false.)" href="../speechrecognition/interimresults/"><code>SpeechRecognition.interimResults</code></a></dt> <dd>Controls whether interim results should be returned (<code>true</code>) or not (<code>false</code>.) Interim results are results that are not yet final (e.g. the <a title="The isFinal read-only property of the SpeechRecognitionResult interface is a Boolean that states whether this result is final (true) or not (false) — if so, then this is the final time this result will be returned; if not, then this result is an interim result, and may be updated later on." href="../speechrecognitionresult/isfinal/"><code>SpeechRecognitionResult.isFinal</code></a> property is <code>false</code>.)</dd> <dt><a title="The maxAlternatives property of the SpeechRecognition interface sets the maximum number of SpeechRecognitionAlternatives provided per SpeechRecognitionResult." href="../speechrecognition/maxalternatives/"><code>SpeechRecognition.maxAlternatives</code></a></dt> <dd>Sets the maximum number of <a title="The SpeechRecognitionAlternative interface of the Web Speech API represents a single word that has been recognised by the speech recognition service." href="../speechrecognitionalternative/"><code>SpeechRecognitionAlternative</code></a>s provided per result. The default value is 1.</dd> <dt><a title="The serviceURI property of the SpeechRecognition interface specifies the location of the speech recognition service used by the current SpeechRecognition to handle the actual recognition. The default is the user agent's default speech service." href="../speechrecognition/serviceuri/"><code>SpeechRecognition.serviceURI</code></a></dt> <dd>Specifies the location of the speech recognition service used by the current <code>SpeechRecognition</code> to handle the actual recognition. The default is the user agent's default speech service.</dd> </dl> <h3 id="Event_handlers">Event handlers</h3> <dl> <dt><a title="The onaudiostart property of the SpeechRecognition interface represents an event handler that will run when the user agent has started to capture audio (when the audiostart event fires.)" href="../speechrecognition/onaudiostart/"><code>SpeechRecognition.onaudiostart</code></a></dt> <dd>Fired when the user agent has started to capture audio.</dd> <dt><a title="The onaudioend property of the SpeechRecognition interface represents an event handler that will run when the user agent has finished capturing audio (when the audioend event fires.)" href="../speechrecognition/onaudioend/"><code>SpeechRecognition.onaudioend</code></a></dt> <dd>Fired when the user agent has finished capturing audio.</dd> <dt><a title="The onend property of the SpeechRecognition interface represents an event handler that will run when the speech recognition service has disconnected (when the end event fires.)" href="../speechrecognition/onend/"><code>SpeechRecognition.onend</code></a></dt> <dd>Fired when the speech recognition service has disconnected.</dd> <dt><a title="The onerror property of the SpeechRecognition interface represents an event handler that will run when a speech recognition error occurs (when the error event fires.)" href="../speechrecognition/onerror/"><code>SpeechRecognition.onerror</code></a></dt> <dd>Fired when a speech recognition error occurs.</dd> <dt><a title="The onnomatch property of the SpeechRecognition interface represents an event handler that will run when the speech recognition service returns a final result with no significant recognition (when the nomatch event fires.)" href="../speechrecognition/onnomatch/"><code>SpeechRecognition.onnomatch</code></a></dt> <dd>Fired when the speech recognition service returns a final result with no significant recognition. This may involve some degree of recognition, which doesn't meet or exceed the <a title="The confidence read-only property of the SpeechRecognitionResult interface returns a numeric estimate of how confident the speech recognition system is that the recognition is correct." href="../speechrecognitionalternative/confidence/"><code>confidence</code></a> threshold.</dd> <dt><a title="The onresult property of the SpeechRecognition interface represents an event handler that will run when the speech recognition service returns a result — a word or phrase has been positively recognized and this has been communicated back to the app (when the result event fires.)" href="../speechrecognition/onresult/"><code>SpeechRecognition.onresult</code></a></dt> <dd>Fired when the speech recognition service returns a result — a word or phrase has been positively recognized and this has been communicated back to the app.</dd> <dt><a title="The onsoundstart property of the SpeechRecognition interface represents an event handler that will run when any sound — recognisable speech or not — has been detected (when the soundstart event fires.)" href="../speechrecognition/onsoundstart/"><code>SpeechRecognition.onsoundstart</code></a></dt> <dd>Fired when any sound — recognisable speech or not — has been detected.</dd> <dt><a title="The onsoundend property of the SpeechRecognition interface represents an event handler that will run when any sound — recognisable speech or not — has stopped being detected (when the soundend event fires.)" href="../speechrecognition/onsoundend/"><code>SpeechRecognition.onsoundend</code></a></dt> <dd>Fired when any sound — recognisable speech or not — has stopped being detected.</dd> <dt><a title="The onspeechstart property of the SpeechRecognition interface represents an event handler that will run when sound recognised by the speech recognition service as speech has been detected (when the speechstart event fires.)" href="../speechrecognition/onspeechstart/"><code>SpeechRecognition.onspeechstart</code></a></dt> <dd>Fired when sound that is recognised by the speech recognition service as speech has been detected.</dd> <dt><a title="The onspeechend property of the SpeechRecognition interface represents an event handler that will run when speech recognised by the speech recognition service has stopped being detected (when the speechend event fires.)" href="../speechrecognition/onspeechend/"><code>SpeechRecognition.onspeechend</code></a></dt> <dd>Fired when speech recognised by the speech recognition service has stopped being detected.</dd> <dt><a title="The onstart property of the SpeechRecognition interface represents an event handler that will run when the speech recognition service has begun listening to incoming audio with intent to recognize grammars associated with the current SpeechRecognition (when the start event fires.)" href="../speechrecognition/onstart/"><code>SpeechRecognition.onstart</code></a></dt> <dd>Fired when the speech recognition service has begun listening to incoming audio with intent to recognize grammars associated with the current <code>SpeechRecognition</code>.</dd> </dl> <h2 id="Methods">Methods</h2> <p><em><code>SpeechRecognition</code> also inherits methods from its parent interface, <a title="EventTarget is an interface implemented by objects that can receive events and may have listeners for them." href="../eventtarget/"><code>EventTarget</code></a>.</em></p> <dl> <dt><a title="The abort() method of the Web Speech API stops the speech recognition service from listening to incoming audio, and doesn't attempt to return a SpeechRecognitionResult." href="../speechrecognition/abort/"><code>SpeechRecognition.abort()</code></a></dt> <dd>Stops the speech recognition service from listening to incoming audio, and doesn't attempt to return a <a title="The SpeechRecognitionResult interface of the Web Speech API represents a single recognition match, which may contain multiple SpeechRecognitionAlternative objects." href="../speechrecognitionresult/"><code>SpeechRecognitionResult</code></a>.</dd> <dt><a title="The start() method of the Web Speech API starts the speech recognition service listening to incoming audio with intent to recognize grammars associated with the current SpeechRecognition." href="../speechrecognition/start/"><code>SpeechRecognition.start()</code></a></dt> <dd>Starts the speech recognition service listening to incoming audio with intent to recognize grammars associated with the current <code>SpeechRecognition</code>.</dd> <dt><a title="The stop() method of the Web Speech API stops the speech recognition service from listening to incoming audio, and attempts to return a SpeechRecognitionResult using the audio captured so far." href="../speechrecognition/stop/"><code>SpeechRecognition.stop()</code></a></dt> <dd>Stops the speech recognition service from listening to incoming audio, and attempts to return a <a title="The SpeechRecognitionResult interface of the Web Speech API represents a single recognition match, which may contain multiple SpeechRecognitionAlternative objects." href="../speechrecognitionresult/"><code>SpeechRecognitionResult</code></a> using the audio captured so far.</dd> </dl> <h2 id="Examples">Examples</h2> <p>In our simple <a href="https://github.com/mdn/web-speech-api/tree/master/speech-color-changer" target="_blank">Speech color changer</a> example, we create a new <code>SpeechRecognition</code> object instance using the <a title="The SpeechRecognition() constructor creates a new SpeechRecognition object instance." href="../speechrecognition/speechrecognition/"><code>SpeechRecognition()</code></a> constructor, create a new <a title="The SpeechGrammarList interface of the Web Speech API represents a list of SpeechGrammar objects containing words or patterns of words that we want the recognition service to recognize." href="../speechgrammarlist/"><code>SpeechGrammarList</code></a>, and set it to be the grammar that will be recognised by the <code>SpeechRecognition</code> instance using the <a title="The grammars property of the SpeechRecognition interface returns and sets a collection of SpeechGrammar objects that represent the grammars that will be understood by the current SpeechRecognition." href="../speechrecognition/grammars/"><code>SpeechRecognition.grammars</code></a> property.</p> <p>After some other values have been defined, we then set it so that the recognition service starts when a click event occurs (see <a title="The start() method of the Web Speech API starts the speech recognition service listening to incoming audio with intent to recognize grammars associated with the current SpeechRecognition." href="../speechrecognition/start/"><code>SpeechRecognition.start()</code></a>.) When a result has been successfully recognised, the <a title="The onresult property of the SpeechRecognition interface represents an event handler that will run when the speech recognition service returns a result — a word or phrase has been positively recognized and this has been communicated back to the app (when the result event fires.)" href="../speechrecognition/onresult/"><code>SpeechRecognition.onresult</code></a> handler fires, we extract the color that was spoken from the event object, and then set the background color of the <a title="The HTML &lt;html&gt; element represents the root (top-level element) of an HTML document, so it is also referred to as the root element. All other elements must be descendants of this element." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/html" target="_blank"><code>&lt;html&gt;</code></a> element to that colour.</p> <pre data-language="js">var grammar = '#JSGF V1.0; grammar colors; public &lt;color&gt; = aqua | azure | beige | bisque | black | blue | brown | chocolate | coral | crimson | cyan | fuchsia | ghostwhite | gold | goldenrod | gray | green | indigo | ivory | khaki | lavender | lime | linen | magenta | maroon | moccasin | navy | olive | orange | orchid | peru | pink | plum | purple | red | salmon | sienna | silver | snow | tan | teal | thistle | tomato | turquoise | violet | white | yellow ;'
var recognition = new SpeechRecognition();
var speechRecognitionList = new SpeechGrammarList();
speechRecognitionList.addFromString(grammar, 1);
recognition.grammars = speechRecognitionList;
//recognition.continuous = false;
recognition.lang = 'en-US';
recognition.interimResults = false;
recognition.maxAlternatives = 1;

var diagnostic = document.querySelector('.output');
var bg = document.querySelector('html');

document.body.onclick = function() {
  recognition.start();
  console.log('Ready to receive a color command.');
}

recognition.onresult = function(event) {
  var color = event.results[0][0].transcript;
  diagnostic.textContent = 'Result received: ' + color;
  bg.style.backgroundColor = color;
}</pre> <h2 id="Specifications">Specifications</h2> <table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a hreflang="en" class="external" lang="en" href="https://dvcs.w3.org/hg/speech-api/raw-file/tip/webspeechapi.html#speechreco-section" target="_blank">Web Speech API<br><small lang="en-US">The definition of 'SpeechRecognition' in that specification.</small></a></td> <td><span class="spec-Draft">Draft</span></td> <td> </td> </tr> </tbody> </table> <h2 id="Browser_compatibility">Browser compatibility</h2>  <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td>33<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes" target="_blank">webkit</a></span> <sup>[1]</sup>
</td> <td>
<span style="color: #f00;">No support</span> <sup>[2]</sup>
</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td><code>continuous</code></td> <td>33 <sup>[1]</sup>
</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android</th> <th>Chrome</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS</th> <th>IE Phone</th> <th>Opera Mobile</th> <th>Safari Mobile</th> </tr> <tr> <td>Basic support</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>
<span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span>[1]</td> <td>44.0 (44)</td> <td>2.5</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> <tr> <td><code>continuous</code></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>
<span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span>[1]</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> </tbody> </table> </div> <ul> <li>[1] Speech recognition interfaces are currently prefixed in Chrome, so you'll need to prefix interface names appropriately, e.g. <code>webkitSpeechRecognition</code>; You'll also need to serve your code through a web server for recognition to work.</li> <li>[2] Can be enabled via the <code>media.webspeech.recognition.enable</code> flag in <a>about:config</a> on mobile. Not implemented at all on Desktop Firefox — see <a title="Expose SpeechRecognition to the web" href="https://bugzilla.mozilla.org/show_bug.cgi?id=1248897" target="_blank">bug 1248897</a>.</li> </ul> <h3 id="Firefox_OS_permissions">Firefox OS permissions</h3> <p>To use speech recognition in an app, you need to specify the following permissions in your <a href="https://developer.mozilla.org/en-US/docs/Web/Apps/Build/Manifest" target="_blank">manifest</a>:</p> <pre data-language="json">"permissions": {
  "audio-capture" : {
    "description" : "Audio capture"
  },
  "speech-recognition" : {
    "description" : "Speech recognition"
  }
}</pre> <p>You also need a privileged app, so you need to include this as well:</p> <pre data-language="json">  "type": "privileged"</pre> <h2 id="See_also">See also</h2> <ul> <li><a href="../web_speech_api/">Web Speech API</a></li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition%24edit" class="_attribution-link" target="_blank">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2005–2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition" class="_attribution-link" target="_blank">https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
