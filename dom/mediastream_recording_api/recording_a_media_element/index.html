
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>MediaStream Recording API&#58; Recording a Media Element - DOM - W3cubDocs</title>
  
  <meta name="description" content="While the article Using the MediaStream Recording API demonstrates using the MediaRecorder interface to capture a MediaStream generated by a &hellip;">
  <meta name="keywords" content="mediastream, recording, api, media, element, -, dom">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/dom/mediastream_recording_api/recording_a_media_element/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/dom.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/dom/" class="_nav-link" title="" style="margin-left:0;">DOM</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _mdn">
				
<h1>MediaStream Recording API: Recording a media element</h1> <p>While the article Using the MediaStream Recording API demonstrates using the <a title="The MediaRecorder interface of the MediaStream Recording API provides functionality to easily record media. It is created by the invocation of the MediaRecorder() constructor." href="../../mediarecorder/"><code>MediaRecorder</code></a> interface to capture a <a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="../../mediastream/"><code>MediaStream</code></a> generated by a hardware device, as returned by <a title="The MediaDevices.getUserMedia() method prompts the user for permission to use one video and/or one audio input device such as a camera or screensharing and/or a microphone. If the user provides permission, then the returned Promise is resolved with the resulting MediaStream object. If the user denies permission, or media is not available, then the promise is rejected with PermissionDeniedError or NotFoundError respectively. Note that it is possible for the returned promise to neither resolve nor reject, as the user is not required to make a choice." href="../../mediadevices/getusermedia/"><code>navigator.mediaDevices.getUserMedia()</code></a>, you can also use an HTML media element (namely <a title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" target="_blank"><code>&lt;audio&gt;</code></a> or <a title="Use the  HTML &lt;video&gt; element to embed video content in a document. The video element contains one or more video sources. To specify a video source, use either the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" target="_blank"><code>&lt;video&gt;</code></a>) as the source of the <code>MediaStream</code> to be recorded. In this article, we'll look at an example that does just that.</p> <div id="Example"> <h2 id="HTML_content">HTML content</h2>  <p>Let's start by looking at the key bits of the HTML. There's a little more than this, but it's just informational rather than being part of the core operation of the app.</p> <pre data-language="html">&lt;div class="left"&gt;
  &lt;div id="startButton" class="button"&gt;
    Start
  &lt;/div&gt;
  &lt;h2&gt;Preview&lt;/h2&gt;
  &lt;video id="preview" width="160" height="120" autoplay muted&gt;&lt;/video&gt;
&lt;/div&gt;
</pre> <p>We present our main interface in two columns. On the left is a start button and a <a title="Use the  HTML &lt;video&gt; element to embed video content in a document. The video element contains one or more video sources. To specify a video source, use either the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" target="_blank"><code>&lt;video&gt;</code></a> element which displays the video preview; this is the video the user's camera sees. Note that the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-autoplay" target="_blank">autoplay</a></code> attribute is used so that as soon as the stream starts to arrive from the camera, it immediately gets displayed, and the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-muted" target="_blank">muted</a></code> attribute is specified to ensure that the sound from the user's microphone isn't output to their speakers, causing an ugly feedback loop.</p> <pre data-language="html">&lt;div class="right"&gt;
  &lt;div id="stopButton" class="button"&gt;
    Stop
  &lt;/div&gt;
  &lt;h2&gt;Recording&lt;/h2&gt;
  &lt;video id="recording" width="160" height="120" controls&gt;&lt;/video&gt;
  &lt;a id="downloadButton" class="button"&gt;
    Download
  &lt;/a&gt;
&lt;/div&gt;
</pre> <p>On the right we see a stop button and the <code>&lt;video&gt;</code> element which will be used to play back the recorded video. Notice that the playback panel doesn't have autoplay set (so the playback doesn't start as soon as media arrives), and it has <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-controls" target="_blank">controls</a></code> set, which tells it to show the user controls to play, pause, and so forth.</p> <p>Below the playback element is a button for downloading the recorded video.</p>  <h2 id="JavaScript_content">JavaScript content</h2> <p>Now let's have a look at the JavaScript code; this is where the majority of the action happens, after all!</p> <h3 id="Setting_up_global_variables">Setting up global variables</h3> <p>We start by establishing some global variables we'll need.</p> <pre data-language="js">let preview = document.getElementById("preview");
let recording = document.getElementById("recording");
let startButton = document.getElementById("startButton");
let stopButton = document.getElementById("stopButton");
let downloadButton = document.getElementById("downloadButton");
let logElement = document.getElementById("log");

let recordingTimeMS = 5000;
</pre> <p>Most of these are references to elements we need to work with. The last, <code>recordingTimeMS</code>, is set to 5000 milliseconds (5 seconds); this specifies the length of the videos we'll record.</p> <h3 id="Utility_functions">Utility functions</h3> <p>Next, we create some utility functions that will get used later.</p> <pre data-language="js">function log(msg) {
  logElement.innerHTML += msg + "\n";
}
</pre> <p>The <code>log()</code> function is used to otuput text strings to a <a title="The HTML &lt;div&gt; element (or HTML Document Division Element) is the generic container for flow content, which does not inherently represent anything. It can be used to group elements for styling purposes (using the class or id attributes), or because they share attribute values, such as lang. It should be used only when no other semantic element (such as &lt;article&gt; or &lt;nav&gt;) is appropriate." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/div" target="_blank"><code>&lt;div&gt;</code></a> so we can share information with the user. Not very pretty but it gets the job done for our purposes.</p> <pre data-language="js">function wait(delayInMS) {
  return new Promise(resolve =&gt; setTimeout(resolve, delayInMS));
}
</pre> <p>The <code>wait()</code> function returns a new <a title="The Promise object is used for asynchronous computations. A Promise represents a value which may be available now, or in the future, or never." href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise" target="_blank"><code>Promise</code></a> which resolves once the specified number of milliseconds have elapsed. It works by using an <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions" target="_blank">arrow function</a> which calls <a title="Calls a function or executes a code snippet after a specified delay." href="../../windoworworkerglobalscope/settimeout/"><code>window.setTimeout()</code></a>, specifying the promise's resolution handler as the timeout handler function. That lets us use promise syntax when using timeouts, which can be very handy when chaining promises, as we'll see later.</p> <h3 id="Starting_media_recording">Starting media recording</h3> <p>The <code>startRecording()</code> function handles starting the recording process:</p> <pre data-language="js">function startRecording(stream, lengthInMS) {
  let recorder = new MediaRecorder(stream);
  let data = [];
 
  recorder.ondataavailable = event =&gt; data.push(event.data);
  recorder.start();
  log(recorder.state + " for " + (lengthInMS/1000) + " seconds...");
 
  let stopped = new Promise((resolve, reject) =&gt; {
    recorder.onstop = resolve;
    recorder.onerror = event =&gt; reject(event.name);
  });

  let recorded = wait(lengthInMS).then(
    () =&gt; recorder.state == "recording" &amp;&amp; recorder.stop()
  );
 
  return Promise.all([
    stopped,
    recorded
  ])
  .then(() =&gt; data);
}
</pre> <p><code>startRecording()</code> takes two input parameters: a <a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="../../mediastream/"><code>MediaStream</code></a> to record from and the length in milliseconds of the recording to make. We always record no more than the specified number of milliseconds of media, although if the media stops before that time is reached, <a title="The MediaRecorder interface of the MediaStream Recording API provides functionality to easily record media. It is created by the invocation of the MediaRecorder() constructor." href="../../mediarecorder/"><code>MediaRecorder</code></a> automatically stops recording as well.</p> <dl> <dt>Line 2</dt> <dd>Creates the <code>MediaRecorder</code> that will handle recording the input <code>stream</code>.</dd> <dt>Line 3</dt> <dd>Creates an empty array, <code>data</code>, which will be used to hold the <a title="Technical review completed." href="../../blob/"><code>Blob</code></a>s of media data provided to our <a title="The MediaRecorder.ondataavailable event handler (part of the MediaStream Recording API) handles the dataavailable event, letting you run code in response to Blob data being made available for use." href="../../mediarecorder/ondataavailable/"><code>ondataavailable</code></a> event handler.</dd> <dt>Line 5</dt> <dd>Sets up the handler for the <code><a title="/en-US/docs/Web/Events/dataavailable" href="https://developer.mozilla.org/en-US/docs/Web/Events/dataavailable" target="_blank">dataavailable</a></code> event. The received event's <code>data</code> property is a <a title="Technical review completed." href="../../blob/"><code>Blob</code></a> that contains the media data. The event handler simply pushes the <code>Blob</code> onto the <code>data</code> array.</dd> <dt>Lines 6-7</dt> <dd>Starts the recording process by calling <a title="The MediaRecorder.start() method (part of the MediaRecorder API) is used to start capturing media into a Blob." href="../../mediarecorder/start/"><code>recorder.start()</code></a>, and outputs a message to the log with the updated state of the recorder and the number of seconds it will be recording.</dd> <dt>Lines 9-12</dt> <dd>Creates a new <a title="The Promise object is used for asynchronous computations. A Promise represents a value which may be available now, or in the future, or never." href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise" target="_blank"><code>Promise</code></a>, named <code>stopped</code>, which is resolved when the <code>MediaRecorder</code>'s <a title="The MediaRecorder.onstop event handler (part of the MediaRecorder API) handles the stop event, allowing you to run code in response to media recording via a MediaRecorder being stopped." href="../../mediarecorder/onstop/"><code>onstop</code></a> event handler is called, and is rejected if its <a title="The MediaRecorder.onerror event handler (part of the MediaRecorder API) handles the DOMError event, allowing you to run code in response to fatal errors occurring that prevent media capture." href="../../mediarecorder/onerror/"><code>onerror</code></a> event handler is called. The rejection handler receives as input the name of the error that occurred.</dd> <dt>Lines 14-16</dt> <dd>Creates a new <code>Promise</code>, named <code>recorded</code>, which is resolved when the specified number of milliseconds have elapsed. Upon resolution, it stops the <code>MediaRecorder</code> if it's recording.</dd> <dt>Lines 18-22</dt> <dd>These lines create a new <code>Promise</code> which is fulfilled when both of the two <code>Promise</code>s (<code>stopped</code> and <code>recorded</code>) have resolved. Once that resolves, the array data is returned by <code>startRecording()</code> to its caller.</dd> </dl> <h3 id="Stopping_the_input_stream">Stopping the input stream</h3> <p>The <code>stop()</code> function simply stops the input media:</p> <pre data-language="js">function stop(stream) {
  stream.getTracks().forEach(track =&gt; track.stop());
}
</pre> <p>This works by calling <a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/getTracks" target="_blank"><code>MediaStream.getTracks()</code></a>, using <a title="The forEach() method executes a provided function once per array element." href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach" target="_blank"><code>forEach()</code></a> to call <a title="The MediaStreamTrack.stop() method stops playing the source associated with the track. Both the source and the track are deassociated. The track state is set to ended." href="../../mediastreamtrack/stop/"><code>MediaStreamTrack.stop()</code></a> on each track in the stream.</p> <h3 id="Getting_an_input_stream_and_setting_up_the_recorder">Getting an input stream and setting up the recorder</h3> <p>Now let's look at the most intricate piece of code in this example: our event handler for clicks on the start button:</p> <pre data-language="js">startButton.addEventListener("click", function() {
  navigator.mediaDevices.getUserMedia({
    video: true,
    audio: true
  }).then(stream =&gt; {
    preview.srcObject = stream;
    downloadButton.href = stream;
    preview.captureStream = preview.captureStream || preview.mozCaptureStream;
    return new Promise(resolve =&gt; preview.onplaying = resolve);
  }).then(() =&gt; startRecording(preview.captureStream(), recordingTimeMS))
  .then (recordedChunks =&gt; {
    let recordedBlob = new Blob(recordedChunks, { type: "video/webm" });
    recording.src = URL.createObjectURL(recordedBlob);
    downloadButton.href = recording.src;
    downloadButton.download = "RecordedVideo.webm";
    
    log("Successfully recorded " + recordedBlob.size + " bytes of " +
        recordedBlob.type + " media.");
  })
  .catch(log);
}, false);</pre> <p>When a <code><a title="/en-US/docs/Web/Events/click" href="https://developer.mozilla.org/en-US/docs/Web/Events/click" target="_blank">click</a></code> event occurs, here's what happens:</p> <dl> <dt>Lines 2-4</dt> <dd>
<a title="The MediaDevices.getUserMedia() method prompts the user for permission to use one video and/or one audio input device such as a camera or screensharing and/or a microphone. If the user provides permission, then the returned Promise is resolved with the resulting MediaStream object. If the user denies permission, or media is not available, then the promise is rejected with PermissionDeniedError or NotFoundError respectively. Note that it is possible for the returned promise to neither resolve nor reject, as the user is not required to make a choice." href="../../mediadevices/getusermedia/"><code>navigator.mediaDevices.getUserMedia()</code></a> is called to request a new <a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="../../mediastream/"><code>MediaStream</code></a> that has both video and audio tracks. This is the stream we'll record.</dd> <dt>Lines 5-9</dt> <dd>When the Promise returned by <code>getUserMedia()</code> is resolved, the preview <a title="Use the  HTML &lt;video&gt; element to embed video content in a document. The video element contains one or more video sources. To specify a video source, use either the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" target="_blank"><code>&lt;video&gt;</code></a> element's <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-srcobject" target="_blank">srcobject</a></code> attribute is set to be the input stream, which causes the video being captured by the user's camera to be displayed in the preview box. Since the <code>&lt;video&gt;</code> element is muted, the audio won't play. The "Download" button's link is then set to refer to the stream as well. Then, in line 8, we arrange for <code>preview.captureStream()</code> to call <code>preview.mozCaptureStream()</code> so that our code will work on Firefox, on which the <a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/captureStream" target="_blank"><code>MediaRecorder.captureStream()</code></a> method is prefixed. Then a new <a title="The Promise interface represents a proxy for a value not necessarily known at its creation time. It allows you to associate handlers to an asynchronous action's eventual success or failure. This lets asynchronous methods return values like synchronous methods: instead of the final value, the asynchronous method returns a promise of having a value at some point in the future." href="https://developer.mozilla.org/en-US/docs/Web/API/Promise" target="_blank"><code>Promise</code></a> which resolves when the preview video starts to play is created and returned.</dd> <dt>Line 10</dt> <dd>When the preview video begins to play, we know there's media to record, so we respond by calling the <code><a href="#Starting_media_recording">startRecording()</a></code> function we created earlier, passing in the preview video stream (as the source media to be recorded) and <code>recordingTimeMS</code> as the number of milliseconds of media to record. As mentioned before, <code>startRecording()</code> returns a <a title="The Promise object is used for asynchronous computations. A Promise represents a value which may be available now, or in the future, or never." href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise" target="_blank"><code>Promise</code></a> whose resolution handler is called (receiving as input an array of <a title="Technical review completed." href="../../blob/"><code>Blob</code></a> objects containing the chunks of recorded media data) once recording has completed.</dd> <dt>Lines 11-15</dt> <dd>The recording process's resolution handler receives as input an array of media data <code>Blob</code>s locally known as <code>recordedChunks</code>. The first thing we do is merge the chunks into a single <a title="Technical review completed." href="../../blob/"><code>Blob</code></a> whose MIME type is <code>"video/webm"</code> by taking advantage of the fact that the <a title="The Blob() constructor returns a new Blob object. The content of the blob consists of the concatenation of the values given in the parameter array." href="../../blob/blob/"><code>Blob()</code></a> constructor concatenates arrays of objects into one object. Then <a title="The URL.createObjectURL() static method creates a DOMString containing an URL representing the object given in parameter. The URL lifetime is tied to the document in the window on which it was created. The new object URL represents the specified File object or Blob object." href="../../url/createobjecturl/"><code>URL.createObjectURL()</code></a> is used to create an URL that references the blob; this is then made the value of the recorded video playback element's <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-src" target="_blank">src</a></code> attribute (so that you can play the video from the blob) as well as the target of the download button's link. <p>Then the download button's <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/a#attr-download" target="_blank">download</a></code> attribute is set. While the <code>download</code> attribute can be a Boolean, you can also set it to a string to use as the name for the downloaded file. So by setting the download link's <code>download</code> attribute to "RecordedVideo.webm", we tell the browser that clicking the button should download a file named <code>"RecordedVideo.webm"</code> whose contents are the recorded video.</p> </dd> <dt>Lines 17-18</dt> <dd>The size and type of the recorded media are output to the log area below the two videos and the download button.</dd> <dt>Line 20</dt> <dd>The <code>catch()</code> for all the <code>Promise</code>s outputs the error to the logging area by calling our <code>log()</code> function.</dd> </dl> <h3 id="Handling_the_stop_button">Handling the stop button</h3> <p>The last bit of code adds a handler for the <code><a title="/en-US/docs/Web/Events/click" href="https://developer.mozilla.org/en-US/docs/Web/Events/click" target="_blank">click</a></code> event on the stop button using <a title="The EventTarget.addEventListener() method registers the specified listener on the EventTarget it's called on. The event target may be an Element in a document, the Document itself, a Window, or any other object that supports events (such as XMLHttpRequest)." href="../../eventtarget/addeventlistener/"><code>addEventListener()</code></a>:</p> <pre data-language="js">stopButton.addEventListener("click", function() {
  stop(preview.srcObject);
}, false);</pre> <p>This simply calls the <code><a href="#Stopping_the_input_stream">stop()</a></code> function we covered earlier.</p> </div> <h2 id="Result">Result</h2> <p>When put all together with the rest of the HTML and the CSS not shown above, it looks and works like this:</p> <p><iframe width="600" frameborder="0" class="live-sample-frame sample-code-frame" src="https://mdn.mozillademos.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element%24samples/Example?revision=1135521" height="440" id="frame_Example"></iframe></p> <p>You can <a href="https://mdn.mozillademos.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element%24samples/Example?revision=1135521" target="_blank">take a look at all the code</a>, including the parts hidden above because they aren't critical to the explanation of how the APIs are being used.</p> <h2 id="See_also">See also</h2> <ul> <li><a href="../../mediastream_recording_api/">MediaStream Recording API</a></li> <li><a href="../using_the_mediastream_recording_api/">Using the MediaStream Recording API</a></li> <li><a href="../../media_streams_api/">Media Capture and Streams API</a></li> </ul>
<div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element%24edit" class="_attribution-link" target="_blank">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    © 2005–2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element" class="_attribution-link" target="_blank">https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
