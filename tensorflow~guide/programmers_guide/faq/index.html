
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Frequently Asked Questions - TensorFlow Guide - W3cubDocs</title>
  
  <meta name="description" content="This document provides answers to some of the frequently asked questions about TensorFlow. If you have a question that is not covered here, you &hellip;">
  <meta name="keywords" content="frequently, asked, questions, -, tensorflow, guide, tensorflow~guide">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/tensorflow~guide/programmers_guide/faq/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/tensorflow~guide.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~guide/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Guide</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _tensorflow">
				
<h1 itemprop="name" class="devsite-page-title"> Frequently Asked Questions </h1>     <p>This document provides answers to some of the frequently asked questions about TensorFlow. If you have a question that is not covered here, you might find an answer on one of the TensorFlow <a href="https://www.tensorflow.org/about/index" target="_blank">community resources</a>.</p> <h2 id="features_and_compatibility">Features and Compatibility</h2> <h4 id="can_i_run_distributed_training_on_multiple_computers">Can I run distributed training on multiple computers?</h4> <p>Yes! TensorFlow gained <a href="../../deploy/distributed/">support for distributed computation</a> in version 0.8. TensorFlow now supports multiple devices (CPUs and GPUs) in one or more computers.</p> <h4 id="does_tensorflow_work_with_python_3">Does TensorFlow work with Python 3?</h4> <p>As of the 0.6.0 release timeframe (Early December 2015), we do support Python 3.3+.</p> <h2 id="building_a_tensorflow_graph">Building a TensorFlow graph</h2> <p>See also the <a href="https://www.tensorflow.org/api_guides/python/framework" target="_blank">API documentation on building graphs</a>.</p> <h4 id="why_does_c_tfmatmula_b_not_execute_the_matrix_multiplication_immediately">Why does <code>c = tf.matmul(a, b)</code> not execute the matrix multiplication immediately?</h4> <p>In the TensorFlow Python API, <code>a</code>, <code>b</code>, and <code>c</code> are <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor" target="_blank"><code>tf.Tensor</code></a> objects. A <code>Tensor</code> object is a symbolic handle to the result of an operation, but does not actually hold the values of the operation's output. Instead, TensorFlow encourages users to build up complicated expressions (such as entire neural networks and its gradients) as a dataflow graph. You then offload the computation of the entire dataflow graph (or a subgraph of it) to a TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/Session" target="_blank"><code>tf.Session</code></a>, which is able to execute the whole computation much more efficiently than executing the operations one-by-one.</p> <h4 id="how_are_devices_named">How are devices named?</h4> <p>The supported device names are <code>"/device:CPU:0"</code> (or <code>"/cpu:0"</code>) for the CPU device, and <code>"/device:GPU:i"</code> (or <code>"/gpu:i"</code>) for the <em>i</em>th GPU device.</p> <h4 id="how_do_i_place_operations_on_a_particular_device">How do I place operations on a particular device?</h4> <p>To place a group of operations on a device, create them within a <a href="https://www.tensorflow.org/api_docs/python/tf/device" target="_blank"><code>with tf.device(name):</code></a> context. See the how-to documentation on <a href="../../tutorials/using_gpu/">using GPUs with TensorFlow</a> for details of how TensorFlow assigns operations to devices, and the <a href="../../tutorials/deep_cnn/">CIFAR-10 tutorial</a> for an example model that uses multiple GPUs.</p> <h4 id="what_are_the_different_types_of_tensors_that_are_available">What are the different types of tensors that are available?</h4> <p>TensorFlow supports a variety of different data types and tensor shapes. See the <a href="../dims_types/">ranks, shapes, and types reference</a> for more details.</p> <h2 id="running_a_tensorflow_computation">Running a TensorFlow computation</h2> <p>See also the <a href="https://www.tensorflow.org/api_guides/python/client" target="_blank">API documentation on running graphs</a>.</p> <h4 id="whats_the_deal_with_feeding_and_placeholders">What's the deal with feeding and placeholders?</h4> <p>Feeding is a mechanism in the TensorFlow Session API that allows you to substitute different values for one or more tensors at run time. The <code>feed_dict</code> argument to <a href="https://www.tensorflow.org/api_docs/python/tf/Session#run" target="_blank"><code>tf.Session.run</code></a> is a dictionary that maps <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor" target="_blank"><code>tf.Tensor</code></a> objects to numpy arrays (and some other types), which will be used as the values of those tensors in the execution of a step.</p> <p>Often, you have certain tensors, such as inputs, that will always be fed. The <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder" target="_blank"><code>tf.placeholder</code></a> op allows you to define tensors that <em>must</em> be fed, and optionally allows you to constrain their shape as well. See the <a href="../../get_started/mnist/beginners/">beginners' MNIST tutorial</a> for an example of how placeholders and feeding can be used to provide the training data for a neural network.</p> <h4 id="what_is_the_difference_between_sessionrun_and_tensoreval">What is the difference between <code>Session.run()</code> and <code>Tensor.eval()</code>?</h4> <p>If <code>t</code> is a <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor" target="_blank"><code>tf.Tensor</code></a> object, <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor#eval" target="_blank"><code>tf.Tensor.eval</code></a> is shorthand for <a href="https://www.tensorflow.org/api_docs/python/tf/Session#run" target="_blank"><code>tf.Session.run</code></a> (where <code>sess</code> is the current <a href="https://www.tensorflow.org/api_docs/python/tf/get_default_session" target="_blank"><code>tf.get_default_session</code></a>. The two following snippets of code are equivalent:</p> <pre class="prettyprint lang-python" data-language="python"># Using `Session.run()`.
sess = tf.Session()
c = tf.constant(5.0)
print sess.run(c)

# Using `Tensor.eval()`.
c = tf.constant(5.0)
with tf.Session():
  print c.eval()
</pre> <p>In the second example, the session acts as a <a href="https://docs.python.org/2.7/reference/compound_stmts.html#with" target="_blank">context manager</a>, which has the effect of installing it as the default session for the lifetime of the <code>with</code> block. The context manager approach can lead to more concise code for simple use cases (like unit tests); if your code deals with multiple graphs and sessions, it may be more straightforward to make explicit calls to <code>Session.run()</code>.</p> <h4 id="do_sessions_have_a_lifetime_what_about_intermediate_tensors">Do Sessions have a lifetime? What about intermediate tensors?</h4> <p>Sessions can own resources, such as <a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank"><code>tf.Variable</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/QueueBase" target="_blank"><code>tf.QueueBase</code></a>, and <a href="https://www.tensorflow.org/api_docs/python/tf/ReaderBase" target="_blank"><code>tf.ReaderBase</code></a>; and these resources can use a significant amount of memory. These resources (and the associated memory) are released when the session is closed, by calling <a href="https://www.tensorflow.org/api_docs/python/tf/Session#close" target="_blank"><code>tf.Session.close</code></a>.</p> <p>The intermediate tensors that are created as part of a call to <a href="https://www.tensorflow.org/api_guides/python/client" target="_blank"><code>Session.run()</code></a> will be freed at or before the end of the call.</p> <h4 id="does_the_runtime_parallelize_parts_of_graph_execution">Does the runtime parallelize parts of graph execution?</h4> <p>The TensorFlow runtime parallelizes graph execution across many different dimensions:</p> <ul> <li>The individual ops have parallel implementations, using multiple cores in a CPU, or multiple threads in a GPU.</li> <li>Independent nodes in a TensorFlow graph can run in parallel on multiple devices, which makes it possible to speed up <a href="../../tutorials/deep_cnn/">CIFAR-10 training using multiple GPUs</a>.</li> <li>The Session API allows multiple concurrent steps (i.e. calls to <a href="https://www.tensorflow.org/api_docs/python/tf/Session#run" target="_blank"><code>tf.Session.run</code></a> in parallel. This enables the runtime to get higher throughput, if a single step does not use all of the resources in your computer.</li> </ul> <h4 id="which_client_languages_are_supported_in_tensorflow">Which client languages are supported in TensorFlow?</h4> <p>TensorFlow is designed to support multiple client languages. Currently, the best-supported client language is <a href="https://www.tensorflow.org/api_docs/python/index" target="_blank">Python</a>. Experimental interfaces for executing and constructing graphs are also available for <a href="https://www.tensorflow.org/api_docs/cc/index.md" target="_blank">C++</a>, <a href="https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary.html" target="_blank">Java</a> and <a href="https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go" target="_blank">Go</a>.</p> <p>TensorFlow also has a <a href="https://www.tensorflow.org/code/tensorflow/c/c_api.h" target="_blank">C-based client API</a> to help build support for more client languages. We invite contributions of new language bindings.</p> <h4 id="does_tensorflow_make_use_of_all_the_devices_gpus_and_cpus_available_on_my_machine">Does TensorFlow make use of all the devices (GPUs and CPUs) available on my machine?</h4> <p>TensorFlow supports multiple GPUs and CPUs. See the how-to documentation on <a href="../../tutorials/using_gpu/">using GPUs with TensorFlow</a> for details of how TensorFlow assigns operations to devices, and the <a href="../../tutorials/deep_cnn/">CIFAR-10 tutorial</a> for an example model that uses multiple GPUs.</p> <p>Note that TensorFlow only uses GPU devices with a compute capability greater than 3.5.</p> <h4 id="why_does_sessionrun_hang_when_using_a_reader_or_a_queue">Why does <code>Session.run()</code> hang when using a reader or a queue?</h4> <p>The <a href="https://www.tensorflow.org/api_docs/python/tf/ReaderBase" target="_blank"><code>tf.ReaderBase</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/QueueBase" target="_blank"><code>tf.QueueBase</code></a> classes provide special operations that can <em>block</em> until input (or free space in a bounded queue) becomes available. These operations allow you to build sophisticated <a href="../reading_data/">input pipelines</a>, at the cost of making the TensorFlow computation somewhat more complicated. See the how-to documentation for <a href="../reading_data/#creating_threads_to_prefetch_using_queuerunner_objects">using <code>QueueRunner</code> objects to drive queues and readers</a> for more information on how to use them.</p> <h2 id="variables">Variables</h2> <p>See also the how-to documentation on <a href="../variables/">variables</a> and <a href="../variable_scope/">variable scopes</a>, and <a href="https://www.tensorflow.org/api_guides/python/state_ops" target="_blank">the API documentation for variables</a>.</p> <h4 id="what_is_the_lifetime_of_a_variable">What is the lifetime of a variable?</h4> <p>A variable is created when you first run the <a href="https://www.tensorflow.org/api_docs/python/tf/Variable#initializer" target="_blank"><code>tf.Variable.initializer</code></a> operation for that variable in a session. It is destroyed when that <a href="https://www.tensorflow.org/api_docs/python/tf/Session#close" target="_blank"><code>tf.Session.close</code></a>.</p> <h4 id="how_do_variables_behave_when_they_are_concurrently_accessed">How do variables behave when they are concurrently accessed?</h4> <p>Variables allow concurrent read and write operations. The value read from a variable may change if it is concurrently updated. By default, concurrent assigment operations to a variable are allowed to run with no mutual exclusion. To acquire a lock when assigning to a variable, pass <code>use_locking=True</code> to <a href="https://www.tensorflow.org/api_docs/python/tf/Variable#assign" target="_blank"><code>tf.Variable.assign</code></a>.</p> <h2 id="tensor_shapes">Tensor shapes</h2> <p>See also the <a href="https://www.tensorflow.org/api_docs/python/tf/TensorShape" target="_blank"><code>tf.TensorShape</code></a>.</p> <h4 id="how_can_i_determine_the_shape_of_a_tensor_in_python">How can I determine the shape of a tensor in Python?</h4> <p>In TensorFlow, a tensor has both a static (inferred) shape and a dynamic (true) shape. The static shape can be read using the <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor#get_shape" target="_blank"><code>tf.Tensor.get_shape</code></a> method: this shape is inferred from the operations that were used to create the tensor, and may be <a href="https://www.tensorflow.org/api_docs/python/tf/TensorShape" target="_blank">partially complete</a>. If the static shape is not fully defined, the dynamic shape of a <code>Tensor</code> <code>t</code> can be determined by evaluating <a href="https://www.tensorflow.org/api_docs/python/tf/shape" target="_blank"><code>tf.shape(t)</code></a>.</p> <h4 id="what_is_the_difference_between_xset_shape_and_x_tfreshapex">What is the difference between <code>x.set_shape()</code> and <code>x = tf.reshape(x)</code>?</h4> <p>The <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor#set_shape" target="_blank"><code>tf.Tensor.set_shape</code></a> method updates the static shape of a <code>Tensor</code> object, and it is typically used to provide additional shape information when this cannot be inferred directly. It does not change the dynamic shape of the tensor.</p> <p>The <a href="https://www.tensorflow.org/api_docs/python/tf/reshape" target="_blank"><code>tf.reshape</code></a> operation creates a new tensor with a different dynamic shape.</p> <h4 id="how_do_i_build_a_graph_that_works_with_variable_batch_sizes">How do I build a graph that works with variable batch sizes?</h4> <p>It is often useful to build a graph that works with variable batch sizes, for example so that the same code can be used for (mini-)batch training, and single-instance inference. The resulting graph can be <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#as_graph_def" target="_blank">saved as a protocol buffer</a> and <a href="https://www.tensorflow.org/api_docs/python/tf/import_graph_def" target="_blank">imported into another program</a>.</p> <p>When building a variable-size graph, the most important thing to remember is not to encode the batch size as a Python constant, but instead to use a symbolic <code>Tensor</code> to represent it. The following tips may be useful:</p> <ul> <li> <p>Use <a href="https://www.tensorflow.org/api_docs/python/array_ops#shape" target="_blank"><code>batch_size = tf.shape(input)[0]</code></a> to extract the batch dimension from a <code>Tensor</code> called <code>input</code>, and store it in a <code>Tensor</code> called <code>batch_size</code>.</p> </li> <li> <p>Use <a href="https://www.tensorflow.org/api_docs/python/tf/reduce_mean" target="_blank"><code>tf.reduce_mean</code></a> instead of <code>tf.reduce_sum(...) / batch_size</code>.</p> </li> <li> <p>If you use <a href="../reading_data/#feeding">placeholders for feeding input</a>, you can specify a variable batch dimension by creating the placeholder with <a href="https://www.tensorflow.org/api_docs/python/io_ops#placeholder" target="_blank"><code>tf.placeholder(..., shape=[None, ...])</code></a>. The <code>None</code> element of the shape corresponds to a variable-sized dimension.</p> </li> </ul> <h2 id="tensorboard">TensorBoard</h2> <h4 id="how_can_i_visualize_a_tensorflow_graph">How can I visualize a TensorFlow graph?</h4> <p>See the <a href="../../get_started/graph_viz/">graph visualization tutorial</a>.</p> <h4 id="what_is_the_simplest_way_to_send_data_to_tensorboard">What is the simplest way to send data to TensorBoard?</h4> <p>Add summary ops to your TensorFlow graph, and write these summaries to a log directory. Then, start TensorBoard using</p> <pre class="prettyprint notranslate" translate="no" data-language="cpp">python tensorflow/tensorboard/tensorboard.py --logdir=path/to/log-directory
</pre> <p>For more details, see the <a href="../../get_started/summaries_and_tensorboard/">Summaries and TensorBoard tutorial</a>.</p> <h4 id="every_time_i_launch_tensorboard_i_get_a_network_security_popup">Every time I launch TensorBoard, I get a network security popup!</h4> <p>You can change TensorBoard to serve on localhost rather than '0.0.0.0' by the flag --host=localhost. This should quiet any security warnings.</p> <h2 id="extending_tensorflow">Extending TensorFlow</h2> <p>See also the how-to documentation for <a href="../../extend/adding_an_op/">adding a new operation to TensorFlow</a>.</p> <h4 id="my_data_is_in_a_custom_format_how_do_i_read_it_using_tensorflow">My data is in a custom format. How do I read it using TensorFlow?</h4> <p>There are two main options for dealing with data in a custom format.</p> <p>The easier option is to write parsing code in Python that transforms the data into a numpy array, then feed a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder" target="_blank"><code>tf.placeholder</code></a> a tensor with that data. See the documentation on <a href="../reading_data/#feeding">using placeholders for input</a> for more details. This approach is easy to get up and running, but the parsing can be a performance bottleneck.</p> <p>The more efficient option is to <a href="../../extend/adding_an_op/">add a new op written in C++</a> that parses your data format. The <a href="../../extend/new_data_formats/">guide to handling new data formats</a> has more information about the steps for doing this.</p> <h4 id="how_do_i_define_an_operation_that_takes_a_variable_number_of_inputs">How do I define an operation that takes a variable number of inputs?</h4> <p>The TensorFlow op registration mechanism allows you to define inputs that are a single tensor, a list of tensors with the same type (for example when adding together a variable-length list of tensors), or a list of tensors with different types (for example when enqueuing a tuple of tensors to a queue). See the how-to documentation for <a href="../../extend/adding_an_op/#list_inputs_and_outputs">adding an op with a list of inputs or outputs</a> for more details of how to define these different input types.</p> <h2 id="miscellaneous">Miscellaneous</h2> <h4 id="what_is_tensorflows_coding_style_convention">What is TensorFlow's coding style convention?</h4> <p>The TensorFlow Python API adheres to the <a href="https://www.python.org/dev/peps/pep-0008/" target="_blank">PEP8</a> conventions.<sup>*</sup> In particular, we use <code>CamelCase</code> names for classes, and <code>snake_case</code> names for functions, methods, and properties. We also adhere to the <a href="https://google.github.io/styleguide/pyguide.html" target="_blank">Google Python style guide</a>.</p> <p>The TensorFlow C++ code base adheres to the <a href="http://google.github.io/styleguide/cppguide.html" target="_blank">Google C++ style guide</a>.</p> <p>(<sup>*</sup> With one exception: we use 2-space indentation instead of 4-space indentation.)</p>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2017 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/programmers_guide/faq" class="_attribution-link" target="_blank">https://www.tensorflow.org/programmers_guide/faq</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
