
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Module&#58; tf.train - TensorFlow Python - W3cubDocs</title>
  
  <meta name="description" content=" Support for training models. See the Training guide. ">
  <meta name="keywords" content="module, tf, train, -, tensorflow, python, tensorflow~python">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/tensorflow~python/tf/train/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/tensorflow~python.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/tensorflow~python/" class="_nav-link" title="" style="margin-left:0;">TensorFlow Python</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _tensorflow">
				
<h1 itemprop="name" class="devsite-page-title"> Module: tf.train </h1>    <h3 id="module_tftrain_1">Module <code>tf.train</code>
</h3> <p>Support for training models. See the <a href="https://www.tensorflow.org/api_guides/python/train" target="_blank">Training</a> guide.</p> <h2 id="members">Members</h2> <p><a href="../train/adadeltaoptimizer/"><code>class AdadeltaOptimizer</code></a>: Optimizer that implements the Adadelta algorithm. </p> <p><a href="../train/adagraddaoptimizer/"><code>class AdagradDAOptimizer</code></a>: Adagrad Dual Averaging algorithm for sparse linear models.</p> <p><a href="../train/adagradoptimizer/"><code>class AdagradOptimizer</code></a>: Optimizer that implements the Adagrad algorithm.</p> <p><a href="../train/adamoptimizer/"><code>class AdamOptimizer</code></a>: Optimizer that implements the Adam algorithm.</p> <p><a href="../train/byteslist/"><code>class BytesList</code></a></p> <p><a href="../train/checkpointsaverhook/"><code>class CheckpointSaverHook</code></a>: Saves checkpoints every N steps or seconds.</p> <p><a href="../train/chiefsessioncreator/"><code>class ChiefSessionCreator</code></a>: Creates a tf.Session for a chief.</p> <p><a href="../train/clusterdef/"><code>class ClusterDef</code></a></p> <p><a href="../train/clusterspec/"><code>class ClusterSpec</code></a>: Represents a cluster as a set of "tasks", organized into "jobs".</p> <p><a href="../train/coordinator/"><code>class Coordinator</code></a>: A coordinator for threads.</p> <p><a href="../train/example/"><code>class Example</code></a></p> <p><a href="../train/exponentialmovingaverage/"><code>class ExponentialMovingAverage</code></a>: Maintains moving averages of variables by employing an exponential decay.</p> <p><a href="../train/feature/"><code>class Feature</code></a></p> <p><a href="../train/featurelist/"><code>class FeatureList</code></a></p> <p><a href="../train/featurelists/"><code>class FeatureLists</code></a></p> <p><a href="../train/features/"><code>class Features</code></a></p> <p><a href="../train/floatlist/"><code>class FloatList</code></a></p> <p><a href="../train/ftrloptimizer/"><code>class FtrlOptimizer</code></a>: Optimizer that implements the FTRL algorithm.</p> <p><a href="../train/globalstepwaiterhook/"><code>class GlobalStepWaiterHook</code></a>: Delay execution until global step reaches to wait_until_step.</p> <p><a href="../train/gradientdescentoptimizer/"><code>class GradientDescentOptimizer</code></a>: Optimizer that implements the gradient descent algorithm.</p> <p><a href="../train/int64list/"><code>class Int64List</code></a></p> <p><a href="../train/jobdef/"><code>class JobDef</code></a></p> <p><a href="../train/loggingtensorhook/"><code>class LoggingTensorHook</code></a>: Prints the given tensors once every N local steps or once every N seconds.</p> <p><a href="../train/looperthread/"><code>class LooperThread</code></a>: A thread that runs code repeatedly, optionally on a timer.</p> <p><a href="../train/momentumoptimizer/"><code>class MomentumOptimizer</code></a>: Optimizer that implements the Momentum algorithm.</p> <p><a href="../train/monitoredsession/"><code>class MonitoredSession</code></a>: Session-like object that handles initialization, recovery and hooks.</p> <p><a href="../train/monitoredtrainingsession/"><code>MonitoredTrainingSession(...)</code></a>: Creates a <code>MonitoredSession</code> for training.</p> <p><a href="../train/nanlossduringtrainingerror/"><code>class NanLossDuringTrainingError</code></a></p> <p><a href="../train/nantensorhook/"><code>class NanTensorHook</code></a>: NaN Loss monitor.</p> <p><a href="../train/newcheckpointreader/"><code>NewCheckpointReader(...)</code></a></p> <p><a href="../train/optimizer/"><code>class Optimizer</code></a>: Base class for optimizers.</p> <p><a href="../train/proximaladagradoptimizer/"><code>class ProximalAdagradOptimizer</code></a>: Optimizer that implements the Proximal Adagrad algorithm.</p> <p><a href="../train/proximalgradientdescentoptimizer/"><code>class ProximalGradientDescentOptimizer</code></a>: Optimizer that implements the proximal gradient descent algorithm.</p> <p><a href="../train/queuerunner/"><code>class QueueRunner</code></a>: Holds a list of enqueue operations for a queue, each to be run in a thread.</p> <p><a href="../train/rmspropoptimizer/"><code>class RMSPropOptimizer</code></a>: Optimizer that implements the RMSProp algorithm.</p> <p><a href="../train/saver/"><code>class Saver</code></a>: Saves and restores variables.</p> <p><a href="../train/saverdef/"><code>class SaverDef</code></a></p> <p><a href="../train/scaffold/"><code>class Scaffold</code></a>: Structure to create or gather pieces commonly needed to train a model.</p> <p><a href="../train/sequenceexample/"><code>class SequenceExample</code></a></p> <p><a href="../train/server/"><code>class Server</code></a>: An in-process TensorFlow server, for use in distributed training.</p> <p><a href="../train/serverdef/"><code>class ServerDef</code></a></p> <p><a href="../train/sessioncreator/"><code>class SessionCreator</code></a>: A factory for tf.Session.</p> <p><a href="../train/sessionmanager/"><code>class SessionManager</code></a>: Training helper that restores from checkpoint and creates session.</p> <p><a href="../train/sessionrunargs/"><code>class SessionRunArgs</code></a>: Represents arguments to be added to a <code>Session.run()</code> call.</p> <p><a href="../train/sessionruncontext/"><code>class SessionRunContext</code></a>: Provides information about the <code>session.run()</code> call being made.</p> <p><a href="../train/sessionrunhook/"><code>class SessionRunHook</code></a>: Hook to extend calls to MonitoredSession.run().</p> <p><a href="../train/sessionrunvalues/"><code>class SessionRunValues</code></a>: Contains the results of <code>Session.run()</code>.</p> <p><a href="../train/singularmonitoredsession/"><code>class SingularMonitoredSession</code></a>: Session-like object that handles initialization, restoring, and hooks.</p> <p><a href="../train/stepcounterhook/"><code>class StepCounterHook</code></a>: Steps per second monitor.</p> <p><a href="../train/stopatstephook/"><code>class StopAtStepHook</code></a>: Monitor to request stop at a specified step.</p> <p><a href="../train/summarysaverhook/"><code>class SummarySaverHook</code></a>: Saves summaries every N steps.</p> <p><a href="../train/supervisor/"><code>class Supervisor</code></a>: A training helper that checkpoints models and computes summaries.</p> <p><a href="../train/syncreplicasoptimizer/"><code>class SyncReplicasOptimizer</code></a>: Class to synchronize, aggregate gradients and pass them to the optimizer.</p> <p><a href="../train/workersessioncreator/"><code>class WorkerSessionCreator</code></a>: Creates a tf.Session for a worker.</p> <p><a href="../train/add_queue_runner/"><code>add_queue_runner(...)</code></a>: Adds a <code>QueueRunner</code> to a collection in the graph.</p> <p><a href="../train/assert_global_step/"><code>assert_global_step(...)</code></a>: Asserts <code>global_step_tensor</code> is a scalar int <code>Variable</code> or <code>Tensor</code>.</p> <p><a href="../train/basic_train_loop/"><code>basic_train_loop(...)</code></a>: Basic loop to train a model.</p> <p><a href="../train/batch/"><code>batch(...)</code></a>: Creates batches of tensors in <code>tensors</code>.</p> <p><a href="../train/batch_join/"><code>batch_join(...)</code></a>: Runs a list of tensors to fill a queue to create batches of examples.</p> <p><a href="../train/checkpoint_exists/"><code>checkpoint_exists(...)</code></a>: Checks whether a V1 or V2 checkpoint exists with the specified prefix.</p> <p><a href="../train/do_quantize_training_on_graphdef/"><code>do_quantize_training_on_graphdef(...)</code></a></p> <p><a href="../train/exponential_decay/"><code>exponential_decay(...)</code></a>: Applies exponential decay to the learning rate.</p> <p><a href="../train/export_meta_graph/"><code>export_meta_graph(...)</code></a>: Returns <code>MetaGraphDef</code> proto. Optionally writes it to filename.</p> <p><a href="../train/generate_checkpoint_state_proto/"><code>generate_checkpoint_state_proto(...)</code></a>: Generates a checkpoint state proto.</p> <p><a href="../train/get_checkpoint_mtimes/"><code>get_checkpoint_mtimes(...)</code></a>: Returns the mtimes (modification timestamps) of the checkpoints.</p> <p><a href="../train/get_checkpoint_state/"><code>get_checkpoint_state(...)</code></a>: Returns CheckpointState proto from the "checkpoint" file.</p> <p><a href="../train/get_global_step/"><code>get_global_step(...)</code></a>: Get the global step tensor.</p> <p><a href="../train/global_step/"><code>global_step(...)</code></a>: Small helper to get the global step.</p> <p><a href="../train/import_meta_graph/"><code>import_meta_graph(...)</code></a>: Recreates a Graph saved in a <code>MetaGraphDef</code> proto.</p> <p><a href="../train/input_producer/"><code>input_producer(...)</code></a>: Output the rows of <code>input_tensor</code> to a queue for an input pipeline.</p> <p><a href="../train/inverse_time_decay/"><code>inverse_time_decay(...)</code></a>: Applies inverse time decay to the initial learning rate.</p> <p><a href="../train/latest_checkpoint/"><code>latest_checkpoint(...)</code></a>: Finds the filename of latest saved checkpoint file.</p> <p><a href="../train/limit_epochs/"><code>limit_epochs(...)</code></a>: Returns tensor <code>num_epochs</code> times and then raises an <code>OutOfRange</code> error.</p> <p><a href="../train/match_filenames_once/"><code>match_filenames_once(...)</code></a>: Save the list of files matching pattern, so it is only computed once.</p> <p><a href="../train/maybe_batch/"><code>maybe_batch(...)</code></a>: Conditionally creates batches of tensors based on <code>keep_input</code>.</p> <p><a href="../train/maybe_batch_join/"><code>maybe_batch_join(...)</code></a>: Runs a list of tensors to conditionally fill a queue to create batches.</p> <p><a href="../train/maybe_shuffle_batch/"><code>maybe_shuffle_batch(...)</code></a>: Creates batches by randomly shuffling conditionally-enqueued tensors.</p> <p><a href="../train/maybe_shuffle_batch_join/"><code>maybe_shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling conditionally-enqueued tensors.</p> <p><a href="../train/natural_exp_decay/"><code>natural_exp_decay(...)</code></a>: Applies natural exponential decay to the initial learning rate.</p> <p><a href="../train/piecewise_constant/"><code>piecewise_constant(...)</code></a>: Piecewise constant from boundaries and interval values.</p> <p><a href="../train/polynomial_decay/"><code>polynomial_decay(...)</code></a>: Applies a polynomial decay to the learning rate.</p> <p><a href="../train/queue_runner/"><code>queue_runner</code></a> module: Create threads to run multiple enqueue ops.</p> <p><a href="../train/range_input_producer/"><code>range_input_producer(...)</code></a>: Produces the integers from 0 to limit-1 in a queue.</p> <p><a href="../train/replica_device_setter/"><code>replica_device_setter(...)</code></a>: Return a <code>device function</code> to use when building a Graph for replicas.</p> <p><a href="../train/shuffle_batch/"><code>shuffle_batch(...)</code></a>: Creates batches by randomly shuffling tensors.</p> <p><a href="../train/shuffle_batch_join/"><code>shuffle_batch_join(...)</code></a>: Create batches by randomly shuffling tensors.</p> <p><a href="../train/slice_input_producer/"><code>slice_input_producer(...)</code></a>: Produces a slice of each <code>Tensor</code> in <code>tensor_list</code>.</p> <p><a href="../train/start_queue_runners/"><code>start_queue_runners(...)</code></a>: Starts all queue runners collected in the graph.</p> <p><a href="../train/string_input_producer/"><code>string_input_producer(...)</code></a>: Output strings (e.g. filenames) to a queue for an input pipeline.</p> <p><a href="../train/summary_iterator/"><code>summary_iterator(...)</code></a>: An iterator for reading <code>Event</code> protocol buffers from an event file.</p> <p><a href="../train/update_checkpoint_state/"><code>update_checkpoint_state(...)</code></a>: Updates the content of the 'checkpoint' file.</p> <p><a href="../train/write_graph/"><code>write_graph(...)</code></a>: Writes a graph proto to a file.</p> <p>Defined in <a href="https://www.tensorflow.org/code/tensorflow/python/training/training.py" target="_blank"><code>tensorflow/python/training/training.py</code></a>.</p>
<div class="_attribution">
  <p class="_attribution-p">
    Â© 2017 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/api_docs/python/tf/train" class="_attribution-link" target="_blank">https://www.tensorflow.org/api_docs/python/tf/train</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
