
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>ensemble.BaggingClassifier() - Scikit-learn - W3cubDocs</title>
  
  <meta name="description" content=" A Bagging classifier. ">
  <meta name="keywords" content="sklearn, ensemble, baggingclassifier, -, scikit-learn, scikit_learn">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/scikit_learn/modules/generated/sklearn.ensemble.baggingclassifier/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/scikit_learn.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/scikit_learn/" class="_nav-link" title="" style="margin-left:0;">scikit-learn</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _sphinx">
				
<h1 id="sklearn-ensemble-baggingclassifier">sklearn.ensemble.BaggingClassifier</h1> <dl class="class"> <dt id="sklearn.ensemble.BaggingClassifier">
<code>class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=None, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L427" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>A Bagging classifier.</p> <p>A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.</p> <p>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting <a class="reference internal" href="#r151" id="id1">[R151]</a>. If samples are drawn with replacement, then the method is known as Bagging <a class="reference internal" href="#r152" id="id2">[R152]</a>. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces <a class="reference internal" href="#r153" id="id3">[R153]</a>. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches <a class="reference internal" href="#r154" id="id4">[R154]</a>.</p> <p>Read more in the <a class="reference internal" href="../../ensemble/#bagging"><span class="std std-ref">User Guide</span></a>.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>base_estimator</strong> : object or None, optional (default=None)</p>  <p>The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a decision tree.</p>  <p><strong>n_estimators</strong> : int, optional (default=10)</p>  <p>The number of base estimators in the ensemble.</p>  <p><strong>max_samples</strong> : int or float, optional (default=1.0)</p>  <dl class="docutils"> <dt>The number of samples to draw from X to train each base estimator.</dt> <dd>
<ul class="first last simple"> <li>If int, then draw <code>max_samples</code> samples.</li> <li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li> </ul> </dd> </dl>  <p><strong>max_features</strong> : int or float, optional (default=1.0)</p>  <dl class="docutils"> <dt>The number of features to draw from X to train each base estimator.</dt> <dd>
<ul class="first last simple"> <li>If int, then draw <code>max_features</code> features.</li> <li>If float, then draw <code>max_features * X.shape[1]</code> features.</li> </ul> </dd> </dl>  <p><strong>bootstrap</strong> : boolean, optional (default=True)</p>  <p>Whether samples are drawn with replacement.</p>  <p><strong>bootstrap_features</strong> : boolean, optional (default=False)</p>  <p>Whether features are drawn with replacement.</p>  <p><strong>oob_score</strong> : bool</p>  <p>Whether to use out-of-bag samples to estimate the generalization error.</p>  <p><strong>warm_start</strong> : bool, optional (default=False)</p>  <p>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble.</p> <div class="versionadded"> <p><span class="versionmodified">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p> </div>  <p><strong>n_jobs</strong> : int, optional (default=1)</p>  <p>The number of jobs to run in parallel for both <code>fit</code> and <code>predict</code>. If -1, then the number of jobs is set to the number of cores.</p>  <p><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)</p>  <p>If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p>  <p><strong>verbose</strong> : int, optional (default=0)</p>  <p>Controls the verbosity of the building process.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Attributes:</th>
<td class="field-body">
<p class="first"><strong>base_estimator_</strong> : estimator</p>  <p>The base estimator from which the ensemble is grown.</p>  <p><strong>estimators_</strong> : list of estimators</p>  <p>The collection of fitted base estimators.</p>  <p><strong>estimators_samples_</strong> : list of arrays</p>  <p>The subset of drawn samples (i.e., the in-bag samples) for each base estimator. Each subset is defined by a boolean mask.</p>  <p><strong>estimators_features_</strong> : list of arrays</p>  <p>The subset of drawn features for each base estimator.</p>  <p><strong>classes_</strong> : array of shape = [n_classes]</p>  <p>The classes labels.</p>  <p><strong>n_classes_</strong> : int or list</p>  <p>The number of classes.</p>  <p><strong>oob_score_</strong> : float</p>  <p>Score of the training dataset obtained using an out-of-bag estimate.</p>  <p><strong>oob_decision_function_</strong> : array of shape = [n_samples, n_classes]</p>  <p>Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, <code>oob_decision_function_</code> might contain NaN.</p>  </td> </tr>  </table> <h4 class="rubric">References</h4> <table class="docutils citation" frame="void" id="r151" rules="none">   <tr>
<td class="label">[R151]</td>
<td>
<em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id5">2</a>)</em> L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r152" rules="none">   <tr>
<td class="label">[R152]</td>
<td>
<em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id6">2</a>)</em> L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r153" rules="none">   <tr>
<td class="label">[R153]</td>
<td>
<em>(<a class="fn-backref" href="#id3">1</a>, <a class="fn-backref" href="#id7">2</a>)</em> T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</td>
</tr>  </table> <table class="docutils citation" frame="void" id="r154" rules="none">   <tr>
<td class="label">[R154]</td>
<td>
<em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id8">2</a>)</em> G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</td>
</tr>  </table> <h4 class="rubric">Methods</h4> <table class="longtable docutils">   <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.decision_function" title="sklearn.ensemble.BaggingClassifier.decision_function"><code>decision_function</code></a>(*args, **kwargs)</td> <td>Average of the decision functions of the base classifiers.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.fit" title="sklearn.ensemble.BaggingClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</td> <td>Build a Bagging ensemble of estimators from the training set (X, y).</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.get_params" title="sklearn.ensemble.BaggingClassifier.get_params"><code>get_params</code></a>([deep])</td> <td>Get parameters for this estimator.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict" title="sklearn.ensemble.BaggingClassifier.predict"><code>predict</code></a>(X)</td> <td>Predict class for X.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_log_proba" title="sklearn.ensemble.BaggingClassifier.predict_log_proba"><code>predict_log_proba</code></a>(X)</td> <td>Predict class log-probabilities for X.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_proba" title="sklearn.ensemble.BaggingClassifier.predict_proba"><code>predict_proba</code></a>(X)</td> <td>Predict class probabilities for X.</td> </tr> <tr class="row-odd">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.score" title="sklearn.ensemble.BaggingClassifier.score"><code>score</code></a>(X, y[, sample_weight])</td> <td>Returns the mean accuracy on the given test data and labels.</td> </tr> <tr class="row-even">
<td>
<a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.set_params" title="sklearn.ensemble.BaggingClassifier.set_params"><code>set_params</code></a>(**params)</td> <td>Set the parameters of this estimator.</td> </tr>  </table> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.__init__">
<code>__init__(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=None, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L545" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.decision_function">
<code>decision_function(*args, **kwargs)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/utils/metaestimators.py#L54" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Average of the decision functions of the base classifiers.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix} of shape = [n_samples, n_features]</p>  <p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : array, shape = [n_samples, k]</p>  <p>The decision function of the input samples. The columns correspond to the classes in sorted order, as they appear in the attribute <code>classes_</code>. Regression and binary classification are special cases with <code>k == 1</code>, otherwise <code>k==n_classes</code>.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="attribute"> <dt id="sklearn.ensemble.BaggingClassifier.estimators_samples_">
<code>estimators_samples_</code> </dt> <dd>
<p>The subset of drawn samples for each base estimator.</p> <p>Returns a dynamically generated list of boolean masks identifying the samples used for for fitting each member of the ensemble, i.e., the in-bag samples.</p> <p>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</p> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L224" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="docutils"> <dt>Build a Bagging ensemble of estimators from the training</dt> <dd>set (X, y).</dd> </dl> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix} of shape = [n_samples, n_features]</p>  <p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p>  <p><strong>y</strong> : array-like, shape = [n_samples]</p>  <p>The target values (class labels in classification, real numbers in regression).</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples] or None</p>  <p>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>self</strong> : object</p>  <p>Returns self.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L220" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>deep: boolean, optional</strong> :</p>  <p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>params</strong> : mapping of string to any</p>  <p>Parameter names mapped to their values.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L623" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class for X.</p> <p>The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix} of shape = [n_samples, n_features]</p>  <p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>y</strong> : array of shape = [n_samples]</p>  <p>The predicted classes.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_log_proba">
<code>predict_log_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L694" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class log-probabilities for X.</p> <p>The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix} of shape = [n_samples, n_features]</p>  <p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>p</strong> : array of shape = [n_samples, n_classes]</p>  <p>The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute <code>classes_</code>.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/ensemble/bagging.py#L645" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class probabilities for X.</p> <p>The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : {array-like, sparse matrix} of shape = [n_samples, n_features]</p>  <p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>p</strong> : array of shape = [n_samples, n_classes]</p>  <p>The class probabilities of the input samples. The order of the classes corresponds to that in the attribute <code>classes_</code>.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L324" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Parameters:</th>
<td class="field-body">
<p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>  <p>Test samples.</p>  <p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>  <p>True labels for X.</p>  <p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>  <p>Sample weights.</p>  </td> </tr> <tr class="field-even field">
<th class="field-name">Returns:</th>
<td class="field-body">
<p class="first"><strong>score</strong> : float</p>  <p>Mean accuracy of self.predict(X) wrt. y.</p>  </td> </tr>  </table> </dd>
</dl> <dl class="method"> <dt id="sklearn.ensemble.BaggingClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/base.py#L257" target="_blank"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list" frame="void" rules="none"> <col class="field-name"> <col class="field-body">  <tr class="field-odd field">
<th class="field-name">Returns:</th>
<td class="field-body">
<strong>self</strong> :</td> </tr>  </table> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    © 2007–2016 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" class="_attribution-link" target="_blank">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html</a>
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
