
<!DOCTYPE HTML>

<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Fprof - Erlang 18 - W3cubDocs</title>
  
  <meta name="description" content=" fprof ">
  <meta name="keywords" content="fprof, -, erlang, erlang~18">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="mobile-web-app-capable" content="yes">
  
  <link rel="canonical" href="http://docs.w3cub.com/erlang~18/lib/tools-2.8.3/doc/html/fprof/">
  <link href="/favicon.png" rel="icon">
  <link type="text/css" rel="stylesheet" href="/assets/application-50364fff564ce3b6327021805f3f00e2957b441cf27f576a7dd4ff63bbc47047.css">
  <script type="text/javascript" src="/assets/application-db64bfd54ceb42be11af7995804cf4902548419ceb79d509b0b7d62c22d98e6f.js"></script>
  <script src="/json/erlang~18.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-71174418-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body>
	<div class="_app">
	<header class="_header">
  
  <form class="_search">
    <input type="search" class="_search-input" placeholder="Search&hellip;" autocomplete="off" autocapitalize="off" autocorrect="off" spellcheck="false" maxlength="20">
    <a class="_search-clear"></a>
    <div class="_search-tag"></div>
  </form>
  
  <a class="_home-link" href="/" ></a>
  <a class="_menu-link"></a>
  <h1 class="_logo">
    <a href="/" class="_nav-link" title="API Documentation Browser">W3cubDocs</a>
  </h1>
  
  <span class="_logo-sub-nav">/</span><span class="_logo-sub-nav"><a href="/erlang~18/" class="_nav-link" title="" style="margin-left:0;">Erlang 18</a></span>
  
  <nav class="_nav">
    <a href="/app/" class="_nav-link ">App</a>
    <a href="/about/" class="_nav-link ">About</a>
  </nav>
</header>
	<section class="_sidebar">
		<div class="_list">
			
		</div>
	</section>
	<section class="_container ">
		<div class="_content">
			<div class="_page _erlang">
				
<h1>fprof</h1> <h2>Module</h2> <p class="REFBODY">fprof</p> <h2>Module summary</h2> <p class="REFBODY">A Time Profiling Tool using trace to file for minimal runtime performance impact.</p> <h2>Description</h2> 
<p>This module is used to profile a program to find out how the execution time is used. Trace to file is used to minimize runtime performance impact. </p> <p>The <code class="code">fprof</code> module uses tracing to collect profiling data, hence there is no need for special compilation of any module to be profiled. When it starts tracing, <code class="code">fprof</code> will erase all previous tracing in the node and set the necessary trace flags on the profiling target processes as well as local call trace on all functions in all loaded modules and all modules to be loaded. <code class="code">fprof</code> erases all tracing in the node when it stops tracing. </p> <p><code class="code">fprof</code> presents both <strong>own time</strong> i.e how much time a function has used for its own execution, and <strong>accumulated time</strong> i.e including called functions. All presented times are collected using trace timestamps. <code class="code">fprof</code> tries to collect cpu time timestamps, if the host machine OS supports it. Therefore the times may be wallclock times and OS scheduling will randomly strike all called functions in a presumably fair way. </p> <p>If, however, the profiling time is short, and the host machine OS does not support high resolution cpu time measurements, some few OS schedulings may show up as ridiculously long execution times for functions doing practically nothing. An example of a function more or less just composing a tuple in about 100 times the normal execution time has been seen, and when the tracing was repeated, the execution time became normal. </p> <p>Profiling is essentially done in 3 steps:</p> <dl> <dt><strong><code class="code">1</code></strong></dt> <dd>Tracing; to file, as mentioned in the previous paragraph. The trace contains entries for function calls, returns to function, process scheduling, other process related (spawn, etc) events, and garbage collection. All trace entries are timestamped.</dd> <dt><strong><code class="code">2</code></strong></dt> <dd>Profiling; the trace file is read, the execution call stack is simulated, and raw profile data is calculated from the simulated call stack and the trace timestamps. The profile data is stored in the <code class="code">fprof</code> server state. During this step the trace data may be dumped in text format to file or console. </dd> <dt><strong><code class="code">3</code></strong></dt> <dd>Analysing; the raw profile data is sorted, filtered and dumped in text format either to file or console. The text format intended to be both readable for a human reader, as well as parsable with the standard erlang parsing tools.</dd> </dl> <p>Since <code class="code">fprof</code> uses trace to file, the runtime performance degradation is minimized, but still far from negligible, especially for programs that use the filesystem heavily by themselves. Where you place the trace file is also important, e.g on Solaris <code class="code">/tmp</code> is usually a good choice since it is essentially a RAM disk, while any NFS (network) mounted disk is a bad idea. </p> <p id="start"><code class="code">fprof</code> can also skip the file step and trace to a tracer process that does the profiling in runtime.  </p>  <h2>Exports</h2> <h3 id="start-0" class="code">start() -&gt; {ok, Pid} | {error, {already_started, Pid}}</h3>  <p>Types:</p>   <pre>Pid = pid()</pre>

<p>Starts the <code class="code">fprof</code> server. </p> <p id="stop">Note that it seldom needs to be started explicitly since it is automatically started by the functions that need a running server.  </p>  <h3 id="stop-0" class="code">stop() -&gt; ok</h3> 
<p>Same as <code class="code">stop(normal)</code>.</p>  <h3 id="stop-1" class="code">stop(Reason) -&gt; ok</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Stops the <code class="code">fprof</code> server. </p> <p>The supplied <code class="code">Reason</code> becomes the exit reason for the server process. Default Any <code class="code">Reason</code> other than <code class="code">kill</code> sends a request to the server and waits for it to clean up, reply and exit. If <code class="code">Reason</code> is <code class="code">kill</code>, the server is bluntly killed. </p> <p>If the <code class="code">fprof</code> server is not running, this function returns immediately with the same return value. </p> <div class="note"> <div class="label">Note</div> <div class="content">

<p>When the <code class="code">fprof</code> server is stopped the collected raw profile data is lost.</p> </div> </div>   <h3 id="apply-2" class="code">apply(Func, Args) -&gt; term()</h3>  <p>Types:</p>      <pre>Func = function() | {Module, Function}
Args = [term()]
Module = atom()
Function = atom()</pre>

<p>Same as <code class="code">apply(Func, Args, [])</code>.</p>  <h3 id="apply-3" class="code">apply(Module, Function, Args) -&gt; term()</h3>  <p>Types:</p>     <pre>Args = [term()]
Module = atom()
Function = atom()</pre>

<p>Same as <code class="code">apply({Module, Function}, Args, [])</code>.</p>  <h3 id="apply-3" class="code">apply(Func, Args, OptionList) -&gt; term()</h3>  <p>Types:</p>        <pre>Func = function() | {Module, Function}
Args = [term()]
OptionList = [Option]
Module = atom()
Function = atom()
Option = continue | start | {procs, PidList} | TraceStartOption</pre>

<p>Calls <code class="code">erlang:apply(Func, Args)</code> surrounded by <code class="code">trace([start, ...])</code> and <code class="code">trace(stop)</code>. </p> <p>Some effort is made to keep the trace clean from unnecessary trace messages; tracing is started and stopped from a spawned process while the <code class="code">erlang:apply/2</code> call is made in the current process, only surrounded by <code class="code">receive</code> and <code class="code">send</code> statements towards the trace starting process. The trace starting process exits when not needed any more. </p> <p>The <code class="code">TraceStartOption</code> is any option allowed for <code class="code">trace/1</code>. The options <code class="code">[start, {procs, [self() | PidList]} | OptList]</code> are given to <code class="code">trace/1</code>, where <code class="code">OptList</code> is <code class="code">OptionList</code> with <code class="code">continue</code>, <code class="code">start</code> and <code class="code">{procs, _}</code> options removed. </p> <p>The <code class="code">continue</code> option inhibits the call to <code class="code">trace(stop)</code> and leaves it up to the caller to stop tracing at a suitable time.</p>  <h3 id="apply-4" class="code">apply(Module, Function, Args, OptionList) -&gt; term()</h3>  <p>Types:</p>     <pre>Module = atom()
Function = atom()
Args = [term()]</pre>

<p>Same as <code class="code">apply({Module, Function}, Args, OptionList)</code>. </p> <p id="trace"><code class="code">OptionList</code> is an option list allowed for <code class="code">apply/3</code>.  </p>  <h3 id="trace-2" class="code">trace(start, Filename) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Same as <code class="code">trace([start, {file, Filename}])</code>.</p>  <h3 id="trace-2" class="code">trace(verbose, Filename) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Same as <code class="code">trace([start, verbose, {file, Filename}])</code>.</p>  <h3 id="trace-2" class="code">trace(OptionName, OptionValue) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">trace([{OptionName, OptionValue}])</code>.</p>  <h3 id="trace-1" class="code">trace(verbose) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Same as <code class="code">trace([start, verbose])</code>.</p>  <h3 id="trace-1" class="code">trace(OptionName) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>    <pre>OptionName = atom()
Reason = term()</pre>

<p>Same as <code class="code">trace([OptionName])</code>.</p>  <h3 id="trace-1" class="code">trace({OptionName, OptionValue}) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">trace([{OptionName, OptionValue}])</code>.</p>  <h3 id="trace-1" class="code">trace([Option]) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>      <pre>Option = start | stop | {procs, PidSpec} | {procs, [PidSpec]} | verbose | {verbose, bool()} | file | {file, Filename} | {tracer, Tracer}
PidSpec = pid() | atom()
Tracer = pid() | port()
Reason = term()</pre>

<p>Starts or stops tracing. </p> <p><code class="code">PidSpec</code> and <code class="code">Tracer</code> are used in calls to <code class="code">erlang:trace(PidSpec, true, [{tracer, Tracer} | Flags])</code>, and <code class="code">Filename</code> is used to call <code class="code">dbg:trace_port(file, Filename)</code>. Please see the appropriate documentation.</p> <p>Option description:</p> <dl> <dt><strong><code class="code">stop</code></strong></dt> <dd>Stops a running <code class="code">fprof</code> trace and clears all tracing from the node. Either option <code class="code">stop</code> or <code class="code">start</code> must be specified, but not both.</dd> <dt><strong><code class="code">start</code></strong></dt> <dd>Clears all tracing from the node and starts a new <code class="code">fprof</code> trace. Either option <code class="code">start</code> or <code class="code">stop</code> must be specified, but not both.</dd> <dt><strong><code class="code">verbose</code>| <code class="code">{verbose, bool()}</code></strong></dt> <dd>The options <code class="code">verbose</code> or <code class="code">{verbose, true}</code> adds some trace flags that <code class="code">fprof</code> does not need, but that may be interesting for general debugging purposes. This option is only allowed with the <code class="code">start</code> option.</dd> <dt><strong><code class="code">cpu_time</code>| <code class="code">{cpu_time, bool()}</code></strong></dt> <dd>The options <code class="code">cpu_time</code> or <code class="code">{cpu_time, true&gt;</code> makes the timestamps in the trace be in CPU time instead of wallclock time which is the default. This option is only allowed with the <code class="code">start</code> option.</dd> <dt><strong><code class="code">{procs, PidSpec}</code>| <code class="code">{procs, [PidSpec]}</code></strong></dt> <dd>Specifies which processes that shall be traced. If this option is not given, the calling process is traced. All processes spawned by the traced processes are also traced. This option is only allowed with the <code class="code">start</code> option.</dd> <dt><strong><code class="code">file</code>| <code class="code">{file, Filename}</code></strong></dt> <dd>Specifies the filename of the trace. If the option <code class="code">file</code> is given, or none of these options are given, the file <code class="code">"fprof.trace"</code> is used. This option is only allowed with the <code class="code">start</code> option, but not with the <code class="code">{tracer, Tracer}</code> option.</dd> <dt><strong><code class="code">{tracer, Tracer}</code></strong></dt> <dd>Specifies that trace to process or port shall be done instead of trace to file. This option is only allowed with the <code class="code">start</code> option, but not with the <code class="code">{file, Filename}</code> option.</dd> </dl>   <h3 id="profile-0" class="code">profile() -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Same as <code class="code">profile([])</code>.</p>  <h3 id="profile-2" class="code">profile(OptionName, OptionValue) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">profile([{OptionName, OptionValue}])</code>.</p>  <h3 id="profile-1" class="code">profile(OptionName) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>    <pre>OptionName = atom()
Reason = term()</pre>

<p>Same as <code class="code">profile([OptionName])</code>.</p>  <h3 id="profile-1" class="code">profile({OptionName, OptionValue}) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">profile([{OptionName, OptionValue}])</code>.</p>  <h3 id="profile-1" class="code">profile([Option]) -&gt; ok | {ok, Tracer} | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>      <pre>Option = file | {file, Filename} | dump | {dump, Dump} | append | start | stop
Dump = pid() | Dumpfile | []
Tracer = pid()
Reason = term()</pre>

<p>Compiles a trace into raw profile data held by the <code class="code">fprof</code> server. </p> <p><code class="code">Dumpfile</code> is used to call <code class="code">file:open/2</code>, and <code class="code">Filename</code> is used to call <code class="code">dbg:trace_port(file, Filename)</code>. Please see the appropriate documentation.</p> <p>Option description:</p> <dl> <dt><strong><code class="code">file</code>| <code class="code">{file, Filename}</code></strong></dt> <dd>Reads the file <code class="code">Filename</code> and creates raw profile data that is stored in RAM by the <code class="code">fprof</code> server. If the option <code class="code">file</code> is given, or none of these options are given, the file <code class="code">"fprof.trace"</code> is read. The call will return when the whole trace has been read with the return value <code class="code">ok</code> if successful. This option is not allowed with the <code class="code">start</code> or <code class="code">stop</code> options.</dd> <dt><strong><code class="code">dump</code>| <code class="code">{dump, Dump}</code></strong></dt> <dd>Specifies the destination for the trace text dump. If this option is not given, no dump is generated, if it is <code class="code">dump</code> the destination will be the caller's group leader, otherwise the destination <code class="code">Dump</code> is either the pid of an I/O device or a filename. And, finally, if the filename is <code class="code">[]</code> - <code class="code">"fprof.dump"</code> is used instead. This option is not allowed with the <code class="code">stop</code> option.</dd> <dt><strong><code class="code">append</code></strong></dt> <dd>Causes the trace text dump to be appended to the destination file. This option is only allowed with the <code class="code">{dump, Dumpfile}</code> option.</dd> <dt><strong><code class="code">start</code></strong></dt> <dd>Starts a tracer process that profiles trace data in runtime. The call will return immediately with the return value <code class="code">{ok, Tracer}</code> if successful. This option is not allowed with the <code class="code">stop</code>, <code class="code">file</code> or <code class="code">{file, Filename}</code> options.</dd> <dt><strong><code class="code">stop</code></strong></dt> <dd>Stops the tracer process that profiles trace data in runtime. The return value will be value <code class="code">ok</code> if successful. This option is not allowed with the <code class="code">start</code>, <code class="code">file</code> or <code class="code">{file, Filename}</code> options.</dd> </dl>   <h3 id="analyse-0" class="code">analyse() -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>   <pre>Reason = term()</pre>

<p>Same as <code class="code">analyse([])</code>.</p>  <h3 id="analyse-2" class="code">analyse(OptionName, OptionValue) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">analyse([{OptionName, OptionValue}])</code>.</p>  <h3 id="analyse-1" class="code">analyse(OptionName) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>    <pre>OptionName = atom()
Reason = term()</pre>

<p>Same as <code class="code">analyse([OptionName])</code>.</p>  <h3 id="analyse-1" class="code">analyse({OptionName, OptionValue}) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>     <pre>OptionName = atom()
OptionValue = term()
Reason = term()</pre>

<p>Same as <code class="code">analyse([{OptionName, OptionValue}])</code>.</p>  <h3 id="analyse-1" class="code">analyse([Option]) -&gt; ok | {error, Reason} | {'EXIT', ServerPid, Reason}</h3>  <p>Types:</p>       <pre>Option = dest | {dest, Dest} | append | {cols, Cols} | callers | {callers, bool()} | no_callers | {sort, SortSpec} | totals | {totals, bool()} | details | {details, bool()} | no_details
Dest = pid() | Destfile
Cols = integer() &gt;= 80
SortSpec = acc | own
Reason = term()</pre>

<p>Analyses raw profile data in the <code class="code">fprof</code> server. If called while there is no raw profile data available, <code class="code">{error, no_profile}</code> is returned. </p> <p><code class="code">Destfile</code> is used to call <code class="code">file:open/2</code>. Please see the appropriate documentation.</p> <p>Option description:</p> <dl> <dt><strong><code class="code">dest</code>| <code class="code">{dest, Dest}</code></strong></dt> <dd>Specifies the destination for the analysis. If this option is not given or it is <code class="code">dest</code>, the destination will be the caller's group leader, otherwise the destination <code class="code">Dest</code> is either the <code class="code">pid()</code> of an I/O device or a filename. And, finally, if the filename is <code class="code">[]</code> - <code class="code">"fprof.analysis"</code> is used instead.</dd> <dt><strong><code class="code">append</code></strong></dt> <dd>Causes the analysis to be appended to the destination file. This option is only allowed with the <code class="code">{dest, Destfile}</code> option.</dd> <dt><strong><code class="code">{cols, Cols}</code></strong></dt> <dd>Specifies the number of columns in the analysis text. If this option is not given the number of columns is set to 80.</dd> <dt><strong><code class="code">callers</code>| <code class="code">{callers, true}</code></strong></dt> <dd>Prints callers and called information in the analysis. This is the default.</dd> <dt><strong><code class="code">{callers, false}</code>| <code class="code">no_callers</code></strong></dt> <dd>Suppresses the printing of callers and called information in the analysis.</dd> <dt><strong><code class="code">{sort, SortSpec}</code></strong></dt> <dd>Specifies if the analysis should be sorted according to the ACC column, which is the default, or the OWN column. See <code class="bold_code"><a href="#analysis">Analysis Format</a></code> below.</dd> <dt><strong><code class="code">totals</code>| <code class="code">{totals, true}</code></strong></dt> <dd>Includes a section containing call statistics for all calls regardless of process, in the analysis.</dd> <dt><strong><code class="code">{totals, false}</code></strong></dt> <dd>Supresses the totals section in the analysis, which is the default.</dd> <dt><strong><code class="code">details</code>| <code class="code">{details, true}</code></strong></dt> <dd>Prints call statistics for each process in the analysis. This is the default.</dd> <dt><strong><code class="code">{details, false}</code>| <code class="code">no_details</code></strong></dt> <dd>Suppresses the call statistics for each process from the analysis.</dd> </dl>  <h2 id="id79284">Analysis format</h2>   <p>This section describes the output format of the analyse command. See <code class="bold_code"><a href="#analyse">analyse/0</a></code>. </p> <p>The format is parsable with the standard Erlang parsing tools <code class="code">erl_scan</code> and <code class="code">erl_parse</code>, <code class="code">file:consult/1</code> or <code class="code">io:read/2</code>. The parse format is not explained here - it should be easy for the interested to try it out. Note that some flags to <code class="code">analyse/1</code> will affect the format. </p> <p>The following example was run on OTP/R8 on Solaris 8, all OTP internals in this example are very version dependent. </p> <p>As an example, we will use the following function, that you may recognise as a slightly modified benchmark function from the manpage file(3):</p> <div class="example"><pre>
-module(foo).
-export([create_file_slow/2]).

create_file_slow(Name, N) when integer(N), N &gt;= 0 -&gt;
    {ok, FD} = 
        file:open(Name, [raw, write, delayed_write, binary]),
    if N &gt; 256 -&gt;
            ok = file:write(FD, 
                            lists:map(fun (X) -&gt; &lt;&lt;X:32/unsigned&gt;&gt; end,
                            lists:seq(0, 255))),
            ok = create_file_slow(FD, 256, N);
       true -&gt;
            ok = create_file_slow(FD, 0, N)
    end,
    ok = file:close(FD).

create_file_slow(FD, M, M) -&gt;
    ok;
create_file_slow(FD, M, N) -&gt;
    ok = file:write(FD, &lt;&lt;M:32/unsigned&gt;&gt;),
    create_file_slow(FD, M+1, N).</pre></div> <p>Let us have a look at the printout after running:</p> <div class="example"><pre>
1&gt; fprof:apply(foo, create_file_slow, [junk, 1024]).
2&gt; fprof:profile().
3&gt; fprof:analyse().</pre></div> <p>The printout starts with:</p> <div class="example"><pre>
%% Analysis results:
{  analysis_options,
 [{callers, true},
  {sort, acc},
  {totals, false},
  {details, true}]}.

%                                       CNT       ACC       OWN        
[{ totals,                             9627, 1691.119, 1659.074}].  %%%</pre></div> <p>The CNT column shows the total number of function calls that was found in the trace. In the ACC column is the total time of the trace from first timestamp to last. And in the OWN column is the sum of the execution time in functions found in the trace, not including called functions. In this case it is very close to the ACC time since the emulator had practically nothing else to do than to execute our test program. </p> <p>All time values in the printout are in milliseconds. </p> <p>The printout continues:</p> <div class="example"><pre>
%                                       CNT       ACC       OWN        
[{ "&lt;0.28.0&gt;",                         9627,undefined, 1659.074}].   %%</pre></div> <p>This is the printout header of one process. The printout contains only this one process since we did <code class="code">fprof:apply/3</code> which traces only the current process. Therefore the CNT and OWN columns perfectly matches the totals above. The ACC column is undefined since summing the ACC times of all calls in the process makes no sense - you would get something like the ACC value from totals above multiplied by the average depth of the call stack, or something. </p> <p>All paragraphs up to the next process header only concerns function calls within this process. </p> <p>Now we come to something more interesting:</p> <div class="example"><pre>
{[{undefined,                             0, 1691.076,    0.030}],     
 { {fprof,apply_start_stop,4},            0, 1691.076,    0.030},     %
 [{{foo,create_file_slow,2},              1, 1691.046,    0.103},      
  {suspend,                               1,    0.000,    0.000}]}.    

{[{{fprof,apply_start_stop,4},            1, 1691.046,    0.103}],     
 { {foo,create_file_slow,2},              1, 1691.046,    0.103},     %
 [{{file,close,1},                        1, 1398.873,    0.019},      
  {{foo,create_file_slow,3},              1,  249.678,    0.029},      
  {{file,open,2},                         1,   20.778,    0.055},      
  {{lists,map,2},                         1,   16.590,    0.043},      
  {{lists,seq,2},                         1,    4.708,    0.017},      
  {{file,write,2},                        1,    0.316,    0.021}]}.    </pre></div> <p>The printout consists of one paragraph per called function. The function <strong>marked</strong> with '%' is the one the paragraph concerns - <code class="code">foo:create_file_slow/2</code>. Above the marked function are the <strong>calling</strong> functions - those that has called the marked, and below are those <strong>called</strong> by the marked function. </p> <p>The paragraphs are per default sorted in decreasing order of the ACC column for the marked function. The calling list and called list within one paragraph are also per default sorted in decreasing order of their ACC column. </p> <p>The columns are: CNT - the number of times the function has been called, ACC - the time spent in the function including called functions, and OWN - the time spent in the function not including called functions. </p> <p>The rows for the <strong>calling</strong> functions contain statistics for the <strong>marked</strong> function with the constraint that only the occasions when a call was made from the <strong>row's</strong> function to the <strong>marked</strong> function are accounted for. </p> <p>The row for the <strong>marked</strong> function simply contains the sum of all <strong>calling</strong> rows. </p> <p>The rows for the <strong>called</strong> functions contains statistics for the <strong>row's</strong> function with the constraint that only the occasions when a call was made from the <strong>marked</strong> to the <strong>row's</strong> function are accounted for. </p> <p>So, we see that <code class="code">foo:create_file_slow/2</code> used very little time for its own execution. It spent most of its time in <code class="code">file:close/1</code>. The function <code class="code">foo:create_file_slow/3</code> that writes 3/4 of the file contents is the second biggest time thief. </p> <p>We also see that the call to <code class="code">file:write/2</code> that writes 1/4 of the file contents takes very little time in itself. What takes time is to build the data (<code class="code">lists:seq/2</code> and <code class="code">lists:map/2</code>). </p> <p>The function 'undefined' that has called <code class="code">fprof:apply_start_stop/4</code> is an unknown function because that call was not recorded in the trace. It was only recorded that the execution returned from <code class="code">fprof:apply_start_stop/4</code> to some other function above in the call stack, or that the process exited from there. </p> <p>Let us continue down the printout to find:</p> <div class="example"><pre>
{[{{foo,create_file_slow,2},              1,  249.678,    0.029},      
  {{foo,create_file_slow,3},            768,    0.000,   23.294}],     
 { {foo,create_file_slow,3},            769,  249.678,   23.323},     %
 [{{file,write,2},                      768,  220.314,   14.539},      
  {suspend,                              57,    6.041,    0.000},      
  {{foo,create_file_slow,3},            768,    0.000,   23.294}]}.    </pre></div> <p>If you compare with the code you will see there also that <code class="code">foo:create_file_slow/3</code> was called only from <code class="code">foo:create_file_slow/2</code> and itself, and called only <code class="code">file:write/2</code>, note the number of calls to <code class="code">file:write/2</code>. But here we see that <code class="code">suspend</code> was called a few times. This is a pseudo function that indicates that the process was suspended while executing in <code class="code">foo:create_file_slow/3</code>, and since there is no <code class="code">receive</code> or <code class="code">erlang:yield/0</code> in the code, it must be Erlang scheduling suspensions, or the trace file driver compensating for large file write operations (these are regarded as a schedule out followed by a schedule in to the same process). </p>  <p>Let us find the <code class="code">suspend</code> entry:</p> <div class="example"><pre>
{[{{file,write,2},                       53,    6.281,    0.000},      
  {{foo,create_file_slow,3},             57,    6.041,    0.000},      
  {{prim_file,drv_command,4},            50,    4.582,    0.000},      
  {{prim_file,drv_get_response,1},       34,    2.986,    0.000},      
  {{lists,map,2},                        10,    2.104,    0.000},      
  {{prim_file,write,2},                  17,    1.852,    0.000},      
  {{erlang,port_command,2},              15,    1.713,    0.000},      
  {{prim_file,drv_command,2},            22,    1.482,    0.000},      
  {{prim_file,translate_response,2},     11,    1.441,    0.000},      
  {{prim_file,'-drv_command/2-fun-0-',1},  15,    1.340,    0.000},      
  {{lists,seq,4},                         3,    0.880,    0.000},      
  {{foo,'-create_file_slow/2-fun-0-',1},   5,    0.523,    0.000},      
  {{erlang,bump_reductions,1},            4,    0.503,    0.000},      
  {{prim_file,open_int_setopts,3},        1,    0.165,    0.000},      
  {{prim_file,i32,4},                     1,    0.109,    0.000},      
  {{fprof,apply_start_stop,4},            1,    0.000,    0.000}],     
 { suspend,                             299,   32.002,    0.000},     %
 [ ]}.</pre></div> <p>We find no particulary long suspend times, so no function seems to have waited in a receive statement. Actually, <code class="code">prim_file:drv_command/4</code> contains a receive statement, but in this test program, the message lies in the process receive buffer when the receive statement is entered. We also see that the total suspend time for the test run is small. </p> <p>The <code class="code">suspend</code> pseudo function has got an OWN time of zero. This is to prevent the process total OWN time from including time in suspension. Whether suspend time is really ACC or OWN time is more of a philosophical question. </p> <p>Now we look at another interesting pseudo function, <code class="code">garbage_collect</code>:</p> <div class="example"><pre>
{[{{prim_file,drv_command,4},            25,    0.873,    0.873},      
  {{prim_file,write,2},                  16,    0.692,    0.692},      
  {{lists,map,2},                         2,    0.195,    0.195}],     
 { garbage_collect,                      43,    1.760,    1.760},     %
 [ ]}.</pre></div> <p>Here we see that no function distinguishes itself considerably, which is very normal. </p> <p>The <code class="code">garbage_collect</code> pseudo function has not got an OWN time of zero like <code class="code">suspend</code>, instead it is equal to the ACC time. </p> <p>Garbage collect often occurs while a process is suspended, but <code class="code">fprof</code> hides this fact by pretending that the suspended function was first unsuspended and then garbage collected. Otherwise the printout would show <code class="code">garbage_collect</code> being called from <code class="code">suspend</code> but not which function that might have caused the garbage collection. </p> <p>Let us now get back to the test code:</p> <div class="example"><pre>
{[{{foo,create_file_slow,3},            768,  220.314,   14.539},      
  {{foo,create_file_slow,2},              1,    0.316,    0.021}],     
 { {file,write,2},                      769,  220.630,   14.560},     %
 [{{prim_file,write,2},                 769,  199.789,   22.573},      
  {suspend,                              53,    6.281,    0.000}]}.    </pre></div> <p>Not unexpectedly, we see that <code class="code">file:write/2</code> was called from <code class="code">foo:create_file_slow/3</code> and <code class="code">foo:create_file_slow/2</code>. The number of calls in each case as well as the used time are also just confirms the previous results. </p> <p>We see that <code class="code">file:write/2</code> only calls <code class="code">prim_file:write/2</code>, but let us refrain from digging into the internals of the kernel application. </p> <p>But, if we nevertheless <strong>do</strong> dig down we find the call to the linked in driver that does the file operations towards the host operating system:</p> <div class="example"><pre>
{[{{prim_file,drv_command,4},           772, 1458.356, 1456.643}],     
 { {erlang,port_command,2},             772, 1458.356, 1456.643},     %
 [{suspend,                              15,    1.713,    0.000}]}.    </pre></div> <p>This is 86 % of the total run time, and as we saw before it is the close operation the absolutely biggest contributor. We find a comparison ratio a little bit up in the call stack:</p> <div class="example"><pre>
{[{{prim_file,close,1},                   1, 1398.748,    0.024},      
  {{prim_file,write,2},                 769,  174.672,   12.810},      
  {{prim_file,open_int,4},                1,   19.755,    0.017},      
  {{prim_file,open_int_setopts,3},        1,    0.147,    0.016}],     
 { {prim_file,drv_command,2},           772, 1593.322,   12.867},     %
 [{{prim_file,drv_command,4},           772, 1578.973,   27.265},      
  {suspend,                              22,    1.482,    0.000}]}.    </pre></div> <p>The time for file operations in the linked in driver distributes itself as 1 % for open, 11 % for write and 87 % for close. All data is probably buffered in the operating system until the close. </p> <p>The unsleeping reader may notice that the ACC times for <code class="code">prim_file:drv_command/2</code> and <code class="code">prim_file:drv_command/4</code> is not equal between the paragraphs above, even though it is easy to believe that <code class="code">prim_file:drv_command/2</code> is just a passthrough function. </p> <p>The missing time can be found in the paragraph for <code class="code">prim_file:drv_command/4</code> where it is evident that not only <code class="code">prim_file:drv_command/2</code> is called but also a fun: </p> <div class="example"><pre>
{[{{prim_file,drv_command,2},           772, 1578.973,   27.265}],     
 { {prim_file,drv_command,4},           772, 1578.973,   27.265},     %
 [{{erlang,port_command,2},             772, 1458.356, 1456.643},      
  {{prim_file,'-drv_command/2-fun-0-',1}, 772,   87.897,   12.736},      
  {suspend,                              50,    4.582,    0.000},      
  {garbage_collect,                      25,    0.873,    0.873}]}.    </pre></div> <p>And some more missing time can be explained by the fact that <code class="code">prim_file:open_int/4</code> both calls <code class="code">prim_file:drv_command/2</code> directly as well as through <code class="code">prim_file:open_int_setopts/3</code>, which complicates the picture. </p> <div class="example"><pre>
{[{{prim_file,open,2},                    1,   20.309,    0.029},      
  {{prim_file,open_int,4},                1,    0.000,    0.057}],     
 { {prim_file,open_int,4},                2,   20.309,    0.086},     %
 [{{prim_file,drv_command,2},             1,   19.755,    0.017},      
  {{prim_file,open_int_setopts,3},        1,    0.360,    0.032},      
  {{prim_file,drv_open,2},                1,    0.071,    0.030},      
  {{erlang,list_to_binary,1},             1,    0.020,    0.020},      
  {{prim_file,i32,1},                     1,    0.017,    0.017},      
  {{prim_file,open_int,4},                1,    0.000,    0.057}]}.    
.
.
.
{[{{prim_file,open_int,4},                1,    0.360,    0.032},      
  {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}],     
 { {prim_file,open_int_setopts,3},        2,    0.360,    0.048},     %
 [{suspend,                               1,    0.165,    0.000},      
  {{prim_file,drv_command,2},             1,    0.147,    0.016},      
  {{prim_file,open_int_setopts,3},        1,    0.000,    0.016}]}.    </pre></div>  <h2 id="id84832">Notes</h2>  <p>The actual supervision of execution times is in itself a CPU intensive activity. A message is written on the trace file for every function call that is made by the profiled code. </p> <p>The ACC time calculation is sometimes difficult to make correct, since it is difficult to define. This happens especially when a function occurs in several instances in the call stack, for example by calling itself perhaps through other functions and perhaps even non-tail recursively. </p> <p>To produce sensible results, <code class="code">fprof</code> tries not to charge any function more than once for ACC time. The instance highest up (with longest duration) in the call stack is chosen. </p> <p>Sometimes a function may unexpectedly waste a lot (some 10 ms or more depending on host machine OS) of OWN (and ACC) time, even functions that does practically nothing at all. The problem may be that the OS has chosen to schedule out the Erlang runtime system process for a while, and if the OS does not support high resolution cpu time measurements <code class="code">fprof</code> will use wallclock time for its calculations, and it will appear as functions randomly burn virtual machine time.</p>  <h2 id="id84871">See Also</h2>  <p>dbg(3), <code class="bold_code"><a href="../eprof/">eprof</a></code>(3), erlang(3), io(3), <code class="bold_code"><a href="../fprof_chapter/">Tools User's Guide</a></code></p>
<div class="_attribution">
  <p class="_attribution-p">
    © 1999–2016 Ericsson AB<br>Licensed under the Apache License, Version 2.0.<br>
    
  </p>
</div>

			</div>
		</div>
	</section>

	</div>
</body>
</html>
